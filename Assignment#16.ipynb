{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network on Forest fires Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('forestfires.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>...</th>\n",
       "      <th>monthfeb</th>\n",
       "      <th>monthjan</th>\n",
       "      <th>monthjul</th>\n",
       "      <th>monthjun</th>\n",
       "      <th>monthmar</th>\n",
       "      <th>monthmay</th>\n",
       "      <th>monthnov</th>\n",
       "      <th>monthoct</th>\n",
       "      <th>monthsep</th>\n",
       "      <th>size_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mar</td>\n",
       "      <td>fri</td>\n",
       "      <td>86.2</td>\n",
       "      <td>26.2</td>\n",
       "      <td>94.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>8.2</td>\n",
       "      <td>51</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>oct</td>\n",
       "      <td>tue</td>\n",
       "      <td>90.6</td>\n",
       "      <td>35.4</td>\n",
       "      <td>669.1</td>\n",
       "      <td>6.7</td>\n",
       "      <td>18.0</td>\n",
       "      <td>33</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oct</td>\n",
       "      <td>sat</td>\n",
       "      <td>90.6</td>\n",
       "      <td>43.7</td>\n",
       "      <td>686.9</td>\n",
       "      <td>6.7</td>\n",
       "      <td>14.6</td>\n",
       "      <td>33</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mar</td>\n",
       "      <td>fri</td>\n",
       "      <td>91.7</td>\n",
       "      <td>33.3</td>\n",
       "      <td>77.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>97</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mar</td>\n",
       "      <td>sun</td>\n",
       "      <td>89.3</td>\n",
       "      <td>51.3</td>\n",
       "      <td>102.2</td>\n",
       "      <td>9.6</td>\n",
       "      <td>11.4</td>\n",
       "      <td>99</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  month  day  FFMC   DMC     DC  ISI  temp  RH  wind  rain  ...  monthfeb  \\\n",
       "0   mar  fri  86.2  26.2   94.3  5.1   8.2  51   6.7   0.0  ...         0   \n",
       "1   oct  tue  90.6  35.4  669.1  6.7  18.0  33   0.9   0.0  ...         0   \n",
       "2   oct  sat  90.6  43.7  686.9  6.7  14.6  33   1.3   0.0  ...         0   \n",
       "3   mar  fri  91.7  33.3   77.5  9.0   8.3  97   4.0   0.2  ...         0   \n",
       "4   mar  sun  89.3  51.3  102.2  9.6  11.4  99   1.8   0.0  ...         0   \n",
       "\n",
       "   monthjan  monthjul  monthjun  monthmar  monthmay  monthnov  monthoct  \\\n",
       "0         0         0         0         1         0         0         0   \n",
       "1         0         0         0         0         0         0         1   \n",
       "2         0         0         0         0         0         0         1   \n",
       "3         0         0         0         1         0         0         0   \n",
       "4         0         0         0         1         0         0         0   \n",
       "\n",
       "   monthsep  size_category  \n",
       "0         0          small  \n",
       "1         0          small  \n",
       "2         0          small  \n",
       "3         0          small  \n",
       "4         0          small  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 517 entries, 0 to 516\n",
      "Data columns (total 31 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   month          517 non-null    object \n",
      " 1   day            517 non-null    object \n",
      " 2   FFMC           517 non-null    float64\n",
      " 3   DMC            517 non-null    float64\n",
      " 4   DC             517 non-null    float64\n",
      " 5   ISI            517 non-null    float64\n",
      " 6   temp           517 non-null    float64\n",
      " 7   RH             517 non-null    int64  \n",
      " 8   wind           517 non-null    float64\n",
      " 9   rain           517 non-null    float64\n",
      " 10  area           517 non-null    float64\n",
      " 11  dayfri         517 non-null    int64  \n",
      " 12  daymon         517 non-null    int64  \n",
      " 13  daysat         517 non-null    int64  \n",
      " 14  daysun         517 non-null    int64  \n",
      " 15  daythu         517 non-null    int64  \n",
      " 16  daytue         517 non-null    int64  \n",
      " 17  daywed         517 non-null    int64  \n",
      " 18  monthapr       517 non-null    int64  \n",
      " 19  monthaug       517 non-null    int64  \n",
      " 20  monthdec       517 non-null    int64  \n",
      " 21  monthfeb       517 non-null    int64  \n",
      " 22  monthjan       517 non-null    int64  \n",
      " 23  monthjul       517 non-null    int64  \n",
      " 24  monthjun       517 non-null    int64  \n",
      " 25  monthmar       517 non-null    int64  \n",
      " 26  monthmay       517 non-null    int64  \n",
      " 27  monthnov       517 non-null    int64  \n",
      " 28  monthoct       517 non-null    int64  \n",
      " 29  monthsep       517 non-null    int64  \n",
      " 30  size_category  517 non-null    object \n",
      "dtypes: float64(8), int64(20), object(3)\n",
      "memory usage: 125.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying PCA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-8.05959472e-01, -1.32332557e+00, -1.83047676e+00, ...,\n",
       "        -4.40225453e-02, -1.72859706e-01, -7.06081245e-01],\n",
       "       [-8.10203395e-03, -1.17954077e+00,  4.88890915e-01, ...,\n",
       "        -4.40225453e-02,  5.78503817e+00, -7.06081245e-01],\n",
       "       [-8.10203395e-03, -1.04982188e+00,  5.60715454e-01, ...,\n",
       "        -4.40225453e-02,  5.78503817e+00, -7.06081245e-01],\n",
       "       ...,\n",
       "       [-1.64008316e+00, -8.46647711e-01,  4.74768113e-01, ...,\n",
       "        -4.40225453e-02, -1.72859706e-01, -7.06081245e-01],\n",
       "       [ 6.80956663e-01,  5.49002541e-01,  2.69382214e-01, ...,\n",
       "        -4.40225453e-02, -1.72859706e-01, -7.06081245e-01],\n",
       "       [-2.02087875e+00, -1.68591332e+00, -1.78044169e+00, ...,\n",
       "         2.27156334e+01, -1.72859706e-01, -7.06081245e-01]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1= df.iloc[:,2:30]\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "\n",
    "sc.fit(df1)\n",
    "df_norm = sc.transform(df1)\n",
    "df_norm                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.76670947e+00, -1.32025451e+00, -8.43971398e-01, ...,\n",
       "        -6.53345819e-02,  4.98037274e-16, -2.73530281e-16],\n",
       "       [ 3.90786263e-01,  8.31061522e-01, -1.10136513e+00, ...,\n",
       "         3.42618601e-02, -9.55928328e-15,  1.15055466e-15],\n",
       "       [ 6.90415596e-01,  1.17774562e+00, -1.22199841e+00, ...,\n",
       "         2.63235187e-02,  2.58690766e-15, -5.66797432e-17],\n",
       "       ...,\n",
       "       [ 9.21634000e-01, -2.64543072e-01,  2.71921606e+00, ...,\n",
       "        -2.97865814e-01, -1.84247930e-16,  2.36645381e-16],\n",
       "       [-1.62054896e+00, -9.78838231e-01,  3.31987355e-01, ...,\n",
       "         3.91949863e-02, -2.30354869e-16,  2.72058887e-16],\n",
       "       [ 4.07590654e+00, -3.67440726e-01, -2.47151775e-01, ...,\n",
       "        -2.50420726e-02,  5.70142521e-17,  8.50237385e-17]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components = 28)\n",
    "pca_values = pca.fit_transform(df_norm)\n",
    "pca_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.35522746e-01, 6.85788793e-02, 6.23572652e-02, 5.32713255e-02,\n",
       "       4.75942360e-02, 4.68009902e-02, 4.37490015e-02, 4.28025164e-02,\n",
       "       4.08875728e-02, 4.01633268e-02, 3.92926854e-02, 3.83232321e-02,\n",
       "       3.64221503e-02, 3.63217289e-02, 3.57856782e-02, 3.50087806e-02,\n",
       "       3.35447704e-02, 3.24777366e-02, 3.04490902e-02, 3.00246758e-02,\n",
       "       2.37167400e-02, 2.08329788e-02, 1.18357869e-02, 8.88449559e-03,\n",
       "       4.55347471e-03, 7.98135931e-04, 2.67271490e-32, 1.95971390e-33])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var = pca.explained_variance_ratio_\n",
    "var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cumulative Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13.55, 20.41, 26.65, 31.98, 36.74, 41.42, 45.79, 50.07, 54.16,\n",
       "       58.18, 62.11, 65.94, 69.58, 73.21, 76.79, 80.29, 83.64, 86.89,\n",
       "       89.93, 92.93, 95.3 , 97.38, 98.56, 99.45, 99.91, 99.99, 99.99,\n",
       "       99.99])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var1 = np.cumsum(np.round(var,decimals = 4)*100)\n",
    "var1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variance plot for PCA components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(var1,color=\"red\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pc1</th>\n",
       "      <th>pc2</th>\n",
       "      <th>pc3</th>\n",
       "      <th>pc4</th>\n",
       "      <th>pc5</th>\n",
       "      <th>pc6</th>\n",
       "      <th>pc7</th>\n",
       "      <th>pc8</th>\n",
       "      <th>pc9</th>\n",
       "      <th>pc10</th>\n",
       "      <th>...</th>\n",
       "      <th>pc16</th>\n",
       "      <th>pc17</th>\n",
       "      <th>pc18</th>\n",
       "      <th>pc19</th>\n",
       "      <th>pc20</th>\n",
       "      <th>pc21</th>\n",
       "      <th>pc22</th>\n",
       "      <th>pc23</th>\n",
       "      <th>pc24</th>\n",
       "      <th>size_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.766709</td>\n",
       "      <td>-1.320255</td>\n",
       "      <td>-0.843971</td>\n",
       "      <td>-1.994738</td>\n",
       "      <td>-1.453359</td>\n",
       "      <td>0.693985</td>\n",
       "      <td>0.308104</td>\n",
       "      <td>-0.019764</td>\n",
       "      <td>0.010161</td>\n",
       "      <td>-0.437314</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.197543</td>\n",
       "      <td>-0.021839</td>\n",
       "      <td>0.688958</td>\n",
       "      <td>0.563603</td>\n",
       "      <td>-0.439596</td>\n",
       "      <td>-0.926619</td>\n",
       "      <td>-0.405425</td>\n",
       "      <td>-0.118719</td>\n",
       "      <td>-0.017933</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.390786</td>\n",
       "      <td>0.831062</td>\n",
       "      <td>-1.101365</td>\n",
       "      <td>1.400671</td>\n",
       "      <td>2.869388</td>\n",
       "      <td>0.965898</td>\n",
       "      <td>-2.795574</td>\n",
       "      <td>0.041095</td>\n",
       "      <td>-0.548879</td>\n",
       "      <td>0.104500</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.503167</td>\n",
       "      <td>0.499649</td>\n",
       "      <td>0.563706</td>\n",
       "      <td>-0.703319</td>\n",
       "      <td>-1.535718</td>\n",
       "      <td>-0.892995</td>\n",
       "      <td>0.836590</td>\n",
       "      <td>0.204975</td>\n",
       "      <td>0.290771</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.690416</td>\n",
       "      <td>1.177746</td>\n",
       "      <td>-1.221998</td>\n",
       "      <td>2.442038</td>\n",
       "      <td>1.090630</td>\n",
       "      <td>0.390801</td>\n",
       "      <td>-1.586675</td>\n",
       "      <td>-2.159336</td>\n",
       "      <td>-0.090580</td>\n",
       "      <td>0.260888</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.545144</td>\n",
       "      <td>-0.658411</td>\n",
       "      <td>-0.423618</td>\n",
       "      <td>0.860550</td>\n",
       "      <td>-1.195230</td>\n",
       "      <td>-0.297870</td>\n",
       "      <td>0.743648</td>\n",
       "      <td>0.081757</td>\n",
       "      <td>0.345915</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.359951</td>\n",
       "      <td>-1.161443</td>\n",
       "      <td>0.385728</td>\n",
       "      <td>-2.118328</td>\n",
       "      <td>-1.949601</td>\n",
       "      <td>1.027664</td>\n",
       "      <td>-0.179422</td>\n",
       "      <td>-0.250227</td>\n",
       "      <td>-0.620329</td>\n",
       "      <td>-1.343189</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.040887</td>\n",
       "      <td>0.017843</td>\n",
       "      <td>0.332572</td>\n",
       "      <td>1.164745</td>\n",
       "      <td>-1.632741</td>\n",
       "      <td>-0.817618</td>\n",
       "      <td>1.523710</td>\n",
       "      <td>-0.342302</td>\n",
       "      <td>-0.378420</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.974329</td>\n",
       "      <td>-0.842626</td>\n",
       "      <td>1.327788</td>\n",
       "      <td>0.038086</td>\n",
       "      <td>-1.124763</td>\n",
       "      <td>-0.574676</td>\n",
       "      <td>-0.777155</td>\n",
       "      <td>0.303635</td>\n",
       "      <td>0.861126</td>\n",
       "      <td>-2.024719</td>\n",
       "      <td>...</td>\n",
       "      <td>0.844431</td>\n",
       "      <td>1.014944</td>\n",
       "      <td>-0.618231</td>\n",
       "      <td>0.822853</td>\n",
       "      <td>-1.794109</td>\n",
       "      <td>-0.723371</td>\n",
       "      <td>2.020419</td>\n",
       "      <td>-0.545591</td>\n",
       "      <td>0.161735</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>-0.087560</td>\n",
       "      <td>0.153964</td>\n",
       "      <td>1.241810</td>\n",
       "      <td>1.536581</td>\n",
       "      <td>0.372425</td>\n",
       "      <td>-1.133422</td>\n",
       "      <td>-0.362287</td>\n",
       "      <td>0.766946</td>\n",
       "      <td>0.818745</td>\n",
       "      <td>-0.289632</td>\n",
       "      <td>...</td>\n",
       "      <td>0.300522</td>\n",
       "      <td>0.513876</td>\n",
       "      <td>0.539642</td>\n",
       "      <td>-0.052958</td>\n",
       "      <td>1.898628</td>\n",
       "      <td>-1.441786</td>\n",
       "      <td>-0.821192</td>\n",
       "      <td>-1.205707</td>\n",
       "      <td>-0.698666</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>0.794366</td>\n",
       "      <td>-0.083966</td>\n",
       "      <td>2.670485</td>\n",
       "      <td>0.284995</td>\n",
       "      <td>0.223323</td>\n",
       "      <td>-0.904232</td>\n",
       "      <td>-0.014849</td>\n",
       "      <td>0.107226</td>\n",
       "      <td>1.340049</td>\n",
       "      <td>-0.147246</td>\n",
       "      <td>...</td>\n",
       "      <td>0.342367</td>\n",
       "      <td>0.485571</td>\n",
       "      <td>0.580150</td>\n",
       "      <td>0.384984</td>\n",
       "      <td>0.086251</td>\n",
       "      <td>-0.970693</td>\n",
       "      <td>-1.353365</td>\n",
       "      <td>-1.254890</td>\n",
       "      <td>-1.212175</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>0.921634</td>\n",
       "      <td>-0.264543</td>\n",
       "      <td>2.719216</td>\n",
       "      <td>-0.019643</td>\n",
       "      <td>0.242195</td>\n",
       "      <td>-0.966939</td>\n",
       "      <td>-0.118080</td>\n",
       "      <td>0.123010</td>\n",
       "      <td>1.290364</td>\n",
       "      <td>-0.177553</td>\n",
       "      <td>...</td>\n",
       "      <td>0.332816</td>\n",
       "      <td>0.344047</td>\n",
       "      <td>0.122409</td>\n",
       "      <td>0.313948</td>\n",
       "      <td>0.211157</td>\n",
       "      <td>-0.777731</td>\n",
       "      <td>-1.736711</td>\n",
       "      <td>-1.154127</td>\n",
       "      <td>-1.230040</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>-1.620549</td>\n",
       "      <td>-0.978838</td>\n",
       "      <td>0.331987</td>\n",
       "      <td>1.256638</td>\n",
       "      <td>-0.408164</td>\n",
       "      <td>0.735698</td>\n",
       "      <td>0.815510</td>\n",
       "      <td>-1.398344</td>\n",
       "      <td>0.076379</td>\n",
       "      <td>-0.005814</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011739</td>\n",
       "      <td>-1.035533</td>\n",
       "      <td>-0.774382</td>\n",
       "      <td>-0.216315</td>\n",
       "      <td>0.515791</td>\n",
       "      <td>0.080575</td>\n",
       "      <td>-0.055548</td>\n",
       "      <td>-0.067502</td>\n",
       "      <td>-0.311027</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>4.075907</td>\n",
       "      <td>-0.367441</td>\n",
       "      <td>-0.247152</td>\n",
       "      <td>0.979966</td>\n",
       "      <td>6.792273</td>\n",
       "      <td>5.943666</td>\n",
       "      <td>-1.639583</td>\n",
       "      <td>8.121827</td>\n",
       "      <td>-0.627980</td>\n",
       "      <td>4.953722</td>\n",
       "      <td>...</td>\n",
       "      <td>10.467443</td>\n",
       "      <td>-7.333036</td>\n",
       "      <td>0.377340</td>\n",
       "      <td>8.870354</td>\n",
       "      <td>-1.074288</td>\n",
       "      <td>2.382433</td>\n",
       "      <td>1.042850</td>\n",
       "      <td>0.296436</td>\n",
       "      <td>0.125099</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>517 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          pc1       pc2       pc3       pc4       pc5       pc6       pc7  \\\n",
       "0    3.766709 -1.320255 -0.843971 -1.994738 -1.453359  0.693985  0.308104   \n",
       "1    0.390786  0.831062 -1.101365  1.400671  2.869388  0.965898 -2.795574   \n",
       "2    0.690416  1.177746 -1.221998  2.442038  1.090630  0.390801 -1.586675   \n",
       "3    3.359951 -1.161443  0.385728 -2.118328 -1.949601  1.027664 -0.179422   \n",
       "4    2.974329 -0.842626  1.327788  0.038086 -1.124763 -0.574676 -0.777155   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "512 -0.087560  0.153964  1.241810  1.536581  0.372425 -1.133422 -0.362287   \n",
       "513  0.794366 -0.083966  2.670485  0.284995  0.223323 -0.904232 -0.014849   \n",
       "514  0.921634 -0.264543  2.719216 -0.019643  0.242195 -0.966939 -0.118080   \n",
       "515 -1.620549 -0.978838  0.331987  1.256638 -0.408164  0.735698  0.815510   \n",
       "516  4.075907 -0.367441 -0.247152  0.979966  6.792273  5.943666 -1.639583   \n",
       "\n",
       "          pc8       pc9      pc10  ...       pc16      pc17      pc18  \\\n",
       "0   -0.019764  0.010161 -0.437314  ...  -0.197543 -0.021839  0.688958   \n",
       "1    0.041095 -0.548879  0.104500  ...  -2.503167  0.499649  0.563706   \n",
       "2   -2.159336 -0.090580  0.260888  ...  -2.545144 -0.658411 -0.423618   \n",
       "3   -0.250227 -0.620329 -1.343189  ...  -0.040887  0.017843  0.332572   \n",
       "4    0.303635  0.861126 -2.024719  ...   0.844431  1.014944 -0.618231   \n",
       "..        ...       ...       ...  ...        ...       ...       ...   \n",
       "512  0.766946  0.818745 -0.289632  ...   0.300522  0.513876  0.539642   \n",
       "513  0.107226  1.340049 -0.147246  ...   0.342367  0.485571  0.580150   \n",
       "514  0.123010  1.290364 -0.177553  ...   0.332816  0.344047  0.122409   \n",
       "515 -1.398344  0.076379 -0.005814  ...  -0.011739 -1.035533 -0.774382   \n",
       "516  8.121827 -0.627980  4.953722  ...  10.467443 -7.333036  0.377340   \n",
       "\n",
       "         pc19      pc20      pc21      pc22      pc23      pc24  size_category  \n",
       "0    0.563603 -0.439596 -0.926619 -0.405425 -0.118719 -0.017933              0  \n",
       "1   -0.703319 -1.535718 -0.892995  0.836590  0.204975  0.290771              0  \n",
       "2    0.860550 -1.195230 -0.297870  0.743648  0.081757  0.345915              0  \n",
       "3    1.164745 -1.632741 -0.817618  1.523710 -0.342302 -0.378420              0  \n",
       "4    0.822853 -1.794109 -0.723371  2.020419 -0.545591  0.161735              0  \n",
       "..        ...       ...       ...       ...       ...       ...            ...  \n",
       "512 -0.052958  1.898628 -1.441786 -0.821192 -1.205707 -0.698666              1  \n",
       "513  0.384984  0.086251 -0.970693 -1.353365 -1.254890 -1.212175              1  \n",
       "514  0.313948  0.211157 -0.777731 -1.736711 -1.154127 -1.230040              1  \n",
       "515 -0.216315  0.515791  0.080575 -0.055548 -0.067502 -0.311027              0  \n",
       "516  8.870354 -1.074288  2.382433  1.042850  0.296436  0.125099              0  \n",
       "\n",
       "[517 rows x 25 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalDf = pd.concat([pd.DataFrame(pca_values[:,0:24],columns=['pc1','pc2','pc3','pc4','pc5','pc6','pc7',\n",
    "                                                             'pc8','pc9','pc10','pc11','pc12','pc13','pc14',\n",
    "                                                             'pc15','pc16','pc17','pc18','pc19','pc20','pc21',\n",
    "                                                             'pc22','pc23','pc24']),\n",
    "                     df[['size_category']]], axis = 1)\n",
    "finalDf.size_category.replace(('large','small'),(1,0),inplace=True)\n",
    "finalDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# spliting into input (X) and output (Y) variables\n",
    "array = finalDf.values\n",
    "X = array[:,0:24]\n",
    "Y = array[:,24]\n",
    "\n",
    "X.reshape(-1,1)\n",
    "Y.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=24, activation='relu'))\n",
    "model.add(Dense(8,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "37/37 [==============================] - 3s 10ms/step - loss: 0.6593 - accuracy: 0.5983 - val_loss: 0.7221 - val_accuracy: 0.6603\n",
      "Epoch 2/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.6042 - accuracy: 0.7424 - val_loss: 0.7190 - val_accuracy: 0.6667\n",
      "Epoch 3/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.5768 - accuracy: 0.7590 - val_loss: 0.7172 - val_accuracy: 0.6731\n",
      "Epoch 4/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.5581 - accuracy: 0.7562 - val_loss: 0.7253 - val_accuracy: 0.6731\n",
      "Epoch 5/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.5419 - accuracy: 0.7590 - val_loss: 0.7240 - val_accuracy: 0.6731\n",
      "Epoch 6/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.5305 - accuracy: 0.7618 - val_loss: 0.7352 - val_accuracy: 0.6731\n",
      "Epoch 7/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.5162 - accuracy: 0.7618 - val_loss: 0.7341 - val_accuracy: 0.6731\n",
      "Epoch 8/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.5061 - accuracy: 0.7618 - val_loss: 0.7284 - val_accuracy: 0.6731\n",
      "Epoch 9/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4976 - accuracy: 0.7618 - val_loss: 0.7327 - val_accuracy: 0.6731\n",
      "Epoch 10/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4897 - accuracy: 0.7618 - val_loss: 0.7465 - val_accuracy: 0.6795\n",
      "Epoch 11/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4823 - accuracy: 0.7645 - val_loss: 0.7494 - val_accuracy: 0.6859\n",
      "Epoch 12/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4751 - accuracy: 0.7645 - val_loss: 0.7508 - val_accuracy: 0.6923\n",
      "Epoch 13/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4684 - accuracy: 0.7673 - val_loss: 0.7576 - val_accuracy: 0.6923\n",
      "Epoch 14/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4606 - accuracy: 0.7701 - val_loss: 0.7607 - val_accuracy: 0.6923\n",
      "Epoch 15/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4554 - accuracy: 0.7701 - val_loss: 0.7672 - val_accuracy: 0.6923\n",
      "Epoch 16/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4489 - accuracy: 0.7701 - val_loss: 0.7578 - val_accuracy: 0.6923\n",
      "Epoch 17/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4435 - accuracy: 0.7729 - val_loss: 0.7691 - val_accuracy: 0.6923\n",
      "Epoch 18/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4394 - accuracy: 0.7812 - val_loss: 0.7496 - val_accuracy: 0.7051\n",
      "Epoch 19/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4331 - accuracy: 0.7756 - val_loss: 0.7650 - val_accuracy: 0.7051\n",
      "Epoch 20/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4275 - accuracy: 0.7812 - val_loss: 0.7649 - val_accuracy: 0.7051\n",
      "Epoch 21/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4233 - accuracy: 0.7922 - val_loss: 0.7597 - val_accuracy: 0.7051\n",
      "Epoch 22/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4172 - accuracy: 0.8006 - val_loss: 0.7760 - val_accuracy: 0.7051\n",
      "Epoch 23/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.4132 - accuracy: 0.7950 - val_loss: 0.7666 - val_accuracy: 0.7051\n",
      "Epoch 24/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.4069 - accuracy: 0.8116 - val_loss: 0.7728 - val_accuracy: 0.7051\n",
      "Epoch 25/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3996 - accuracy: 0.8310 - val_loss: 0.7654 - val_accuracy: 0.7051\n",
      "Epoch 26/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3925 - accuracy: 0.8366 - val_loss: 0.7644 - val_accuracy: 0.7051\n",
      "Epoch 27/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3873 - accuracy: 0.8393 - val_loss: 0.7731 - val_accuracy: 0.7051\n",
      "Epoch 28/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3812 - accuracy: 0.8366 - val_loss: 0.7757 - val_accuracy: 0.7051\n",
      "Epoch 29/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3743 - accuracy: 0.8366 - val_loss: 0.7767 - val_accuracy: 0.7051\n",
      "Epoch 30/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3684 - accuracy: 0.8421 - val_loss: 0.7750 - val_accuracy: 0.7051\n",
      "Epoch 31/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3643 - accuracy: 0.8449 - val_loss: 0.7860 - val_accuracy: 0.7051\n",
      "Epoch 32/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.3549 - accuracy: 0.8560 - val_loss: 0.7740 - val_accuracy: 0.7115\n",
      "Epoch 33/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3484 - accuracy: 0.8587 - val_loss: 0.7833 - val_accuracy: 0.7115\n",
      "Epoch 34/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3426 - accuracy: 0.8643 - val_loss: 0.7778 - val_accuracy: 0.7115\n",
      "Epoch 35/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3375 - accuracy: 0.8615 - val_loss: 0.7847 - val_accuracy: 0.7115\n",
      "Epoch 36/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3310 - accuracy: 0.8726 - val_loss: 0.7872 - val_accuracy: 0.6987\n",
      "Epoch 37/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3253 - accuracy: 0.8726 - val_loss: 0.7834 - val_accuracy: 0.7051\n",
      "Epoch 38/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3203 - accuracy: 0.8837 - val_loss: 0.7777 - val_accuracy: 0.7051\n",
      "Epoch 39/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3154 - accuracy: 0.8809 - val_loss: 0.7859 - val_accuracy: 0.6987\n",
      "Epoch 40/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3100 - accuracy: 0.8781 - val_loss: 0.7991 - val_accuracy: 0.7051\n",
      "Epoch 41/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3054 - accuracy: 0.8864 - val_loss: 0.7910 - val_accuracy: 0.7051\n",
      "Epoch 42/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.3003 - accuracy: 0.8892 - val_loss: 0.7998 - val_accuracy: 0.7179\n",
      "Epoch 43/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2947 - accuracy: 0.8892 - val_loss: 0.8007 - val_accuracy: 0.7115\n",
      "Epoch 44/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2909 - accuracy: 0.8864 - val_loss: 0.7950 - val_accuracy: 0.7179\n",
      "Epoch 45/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2850 - accuracy: 0.8947 - val_loss: 0.7914 - val_accuracy: 0.7244\n",
      "Epoch 46/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2833 - accuracy: 0.8864 - val_loss: 0.7876 - val_accuracy: 0.7115\n",
      "Epoch 47/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2758 - accuracy: 0.8947 - val_loss: 0.8060 - val_accuracy: 0.7179\n",
      "Epoch 48/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2715 - accuracy: 0.8947 - val_loss: 0.8050 - val_accuracy: 0.7244\n",
      "Epoch 49/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2671 - accuracy: 0.9030 - val_loss: 0.8050 - val_accuracy: 0.7308\n",
      "Epoch 50/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2637 - accuracy: 0.9003 - val_loss: 0.8034 - val_accuracy: 0.7436\n",
      "Epoch 51/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2628 - accuracy: 0.8947 - val_loss: 0.8030 - val_accuracy: 0.7308\n",
      "Epoch 52/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2545 - accuracy: 0.9030 - val_loss: 0.8146 - val_accuracy: 0.7372\n",
      "Epoch 53/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2491 - accuracy: 0.9030 - val_loss: 0.8139 - val_accuracy: 0.7179\n",
      "Epoch 54/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2462 - accuracy: 0.9086 - val_loss: 0.8161 - val_accuracy: 0.7244\n",
      "Epoch 55/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2418 - accuracy: 0.9058 - val_loss: 0.8198 - val_accuracy: 0.7115\n",
      "Epoch 56/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2397 - accuracy: 0.9086 - val_loss: 0.8315 - val_accuracy: 0.7179\n",
      "Epoch 57/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2359 - accuracy: 0.9141 - val_loss: 0.8225 - val_accuracy: 0.7115\n",
      "Epoch 58/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2354 - accuracy: 0.9114 - val_loss: 0.8287 - val_accuracy: 0.7115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2289 - accuracy: 0.9058 - val_loss: 0.8426 - val_accuracy: 0.7179\n",
      "Epoch 60/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2243 - accuracy: 0.9141 - val_loss: 0.8330 - val_accuracy: 0.7051\n",
      "Epoch 61/150\n",
      "37/37 [==============================] - 0s 985us/step - loss: 0.2199 - accuracy: 0.9169 - val_loss: 0.8349 - val_accuracy: 0.7051\n",
      "Epoch 62/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2243 - accuracy: 0.9169 - val_loss: 0.8274 - val_accuracy: 0.7308\n",
      "Epoch 63/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.2148 - accuracy: 0.9197 - val_loss: 0.8420 - val_accuracy: 0.7179\n",
      "Epoch 64/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2104 - accuracy: 0.9197 - val_loss: 0.8471 - val_accuracy: 0.7051\n",
      "Epoch 65/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2093 - accuracy: 0.9224 - val_loss: 0.8551 - val_accuracy: 0.7115\n",
      "Epoch 66/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2037 - accuracy: 0.9280 - val_loss: 0.8507 - val_accuracy: 0.7051\n",
      "Epoch 67/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2012 - accuracy: 0.9252 - val_loss: 0.8578 - val_accuracy: 0.7115\n",
      "Epoch 68/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.2005 - accuracy: 0.9307 - val_loss: 0.8616 - val_accuracy: 0.6923\n",
      "Epoch 69/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1929 - accuracy: 0.9307 - val_loss: 0.8677 - val_accuracy: 0.7051\n",
      "Epoch 70/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.1901 - accuracy: 0.9335 - val_loss: 0.8634 - val_accuracy: 0.7179\n",
      "Epoch 71/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.1879 - accuracy: 0.9307 - val_loss: 0.8727 - val_accuracy: 0.7115\n",
      "Epoch 72/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.1865 - accuracy: 0.9307 - val_loss: 0.8705 - val_accuracy: 0.7051\n",
      "Epoch 73/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.1814 - accuracy: 0.9307 - val_loss: 0.8726 - val_accuracy: 0.6987\n",
      "Epoch 74/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.1791 - accuracy: 0.9391 - val_loss: 0.8771 - val_accuracy: 0.7051\n",
      "Epoch 75/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1753 - accuracy: 0.9335 - val_loss: 0.8703 - val_accuracy: 0.6987\n",
      "Epoch 76/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.1739 - accuracy: 0.9391 - val_loss: 0.8770 - val_accuracy: 0.7051\n",
      "Epoch 77/150\n",
      "37/37 [==============================] - 0s 862us/step - loss: 0.1732 - accuracy: 0.9391 - val_loss: 0.8879 - val_accuracy: 0.7115\n",
      "Epoch 78/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.1672 - accuracy: 0.9391 - val_loss: 0.8953 - val_accuracy: 0.7115\n",
      "Epoch 79/150\n",
      "37/37 [==============================] - 0s 974us/step - loss: 0.1653 - accuracy: 0.9446 - val_loss: 0.8967 - val_accuracy: 0.7244\n",
      "Epoch 80/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.1626 - accuracy: 0.9363 - val_loss: 0.8934 - val_accuracy: 0.7179\n",
      "Epoch 81/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.1601 - accuracy: 0.9418 - val_loss: 0.9009 - val_accuracy: 0.7179\n",
      "Epoch 82/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.1563 - accuracy: 0.9446 - val_loss: 0.9062 - val_accuracy: 0.7179\n",
      "Epoch 83/150\n",
      "37/37 [==============================] - 0s 981us/step - loss: 0.1542 - accuracy: 0.9418 - val_loss: 0.9112 - val_accuracy: 0.7244\n",
      "Epoch 84/150\n",
      "37/37 [==============================] - 0s 988us/step - loss: 0.1510 - accuracy: 0.9446 - val_loss: 0.9070 - val_accuracy: 0.7308\n",
      "Epoch 85/150\n",
      "37/37 [==============================] - 0s 980us/step - loss: 0.1484 - accuracy: 0.9446 - val_loss: 0.9102 - val_accuracy: 0.7308\n",
      "Epoch 86/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.1459 - accuracy: 0.9501 - val_loss: 0.9076 - val_accuracy: 0.7244\n",
      "Epoch 87/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.1427 - accuracy: 0.9584 - val_loss: 0.9196 - val_accuracy: 0.7244\n",
      "Epoch 88/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.1400 - accuracy: 0.9584 - val_loss: 0.9170 - val_accuracy: 0.7436\n",
      "Epoch 89/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.1398 - accuracy: 0.9529 - val_loss: 0.9187 - val_accuracy: 0.7308\n",
      "Epoch 90/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.1350 - accuracy: 0.9640 - val_loss: 0.9284 - val_accuracy: 0.7436\n",
      "Epoch 91/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1332 - accuracy: 0.9612 - val_loss: 0.9359 - val_accuracy: 0.7372\n",
      "Epoch 92/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.1320 - accuracy: 0.9529 - val_loss: 0.9388 - val_accuracy: 0.7436\n",
      "Epoch 93/150\n",
      "37/37 [==============================] - 0s 952us/step - loss: 0.1320 - accuracy: 0.9584 - val_loss: 0.9576 - val_accuracy: 0.7308\n",
      "Epoch 94/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.1274 - accuracy: 0.9584 - val_loss: 0.9485 - val_accuracy: 0.7564\n",
      "Epoch 95/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.1275 - accuracy: 0.9612 - val_loss: 0.9544 - val_accuracy: 0.7436\n",
      "Epoch 96/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.1212 - accuracy: 0.9668 - val_loss: 0.9509 - val_accuracy: 0.7564\n",
      "Epoch 97/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.1201 - accuracy: 0.9640 - val_loss: 0.9527 - val_accuracy: 0.7692\n",
      "Epoch 98/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.1179 - accuracy: 0.9668 - val_loss: 0.9559 - val_accuracy: 0.7692\n",
      "Epoch 99/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.1199 - accuracy: 0.9557 - val_loss: 0.9550 - val_accuracy: 0.7692\n",
      "Epoch 100/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.1158 - accuracy: 0.9668 - val_loss: 0.9685 - val_accuracy: 0.7692\n",
      "Epoch 101/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.1190 - accuracy: 0.9640 - val_loss: 0.9723 - val_accuracy: 0.7692\n",
      "Epoch 102/150\n",
      "37/37 [==============================] - 0s 993us/step - loss: 0.1144 - accuracy: 0.9557 - val_loss: 0.9710 - val_accuracy: 0.7821\n",
      "Epoch 103/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.1087 - accuracy: 0.9723 - val_loss: 0.9737 - val_accuracy: 0.7885\n",
      "Epoch 104/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.1062 - accuracy: 0.9751 - val_loss: 0.9815 - val_accuracy: 0.7885\n",
      "Epoch 105/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.1048 - accuracy: 0.9723 - val_loss: 0.9768 - val_accuracy: 0.7885\n",
      "Epoch 106/150\n",
      "37/37 [==============================] - 0s 952us/step - loss: 0.1031 - accuracy: 0.9668 - val_loss: 0.9792 - val_accuracy: 0.7949\n",
      "Epoch 107/150\n",
      "37/37 [==============================] - 0s 945us/step - loss: 0.1027 - accuracy: 0.9668 - val_loss: 0.9832 - val_accuracy: 0.8077\n",
      "Epoch 108/150\n",
      "37/37 [==============================] - 0s 986us/step - loss: 0.1019 - accuracy: 0.9751 - val_loss: 0.9818 - val_accuracy: 0.7885\n",
      "Epoch 109/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.0994 - accuracy: 0.9751 - val_loss: 0.9932 - val_accuracy: 0.7949\n",
      "Epoch 110/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0959 - accuracy: 0.9723 - val_loss: 0.9862 - val_accuracy: 0.7885\n",
      "Epoch 111/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0948 - accuracy: 0.9778 - val_loss: 0.9914 - val_accuracy: 0.7949\n",
      "Epoch 112/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.0936 - accuracy: 0.9723 - val_loss: 0.9945 - val_accuracy: 0.7949\n",
      "Epoch 113/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.0920 - accuracy: 0.9723 - val_loss: 0.9893 - val_accuracy: 0.8013\n",
      "Epoch 114/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.0886 - accuracy: 0.9751 - val_loss: 1.0083 - val_accuracy: 0.8077\n",
      "Epoch 115/150\n",
      "37/37 [==============================] - 0s 877us/step - loss: 0.0880 - accuracy: 0.9723 - val_loss: 1.0091 - val_accuracy: 0.8077\n",
      "Epoch 116/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 1ms/step - loss: 0.0864 - accuracy: 0.9751 - val_loss: 1.0145 - val_accuracy: 0.8077\n",
      "Epoch 117/150\n",
      "37/37 [==============================] - 0s 906us/step - loss: 0.0845 - accuracy: 0.9751 - val_loss: 1.0215 - val_accuracy: 0.8013\n",
      "Epoch 118/150\n",
      "37/37 [==============================] - 0s 984us/step - loss: 0.0829 - accuracy: 0.9778 - val_loss: 1.0155 - val_accuracy: 0.8141\n",
      "Epoch 119/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.0819 - accuracy: 0.9751 - val_loss: 1.0237 - val_accuracy: 0.8141\n",
      "Epoch 120/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.0832 - accuracy: 0.9778 - val_loss: 1.0451 - val_accuracy: 0.8141\n",
      "Epoch 121/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.0780 - accuracy: 0.9751 - val_loss: 1.0398 - val_accuracy: 0.8141\n",
      "Epoch 122/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.0787 - accuracy: 0.9778 - val_loss: 1.0586 - val_accuracy: 0.8141\n",
      "Epoch 123/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.0783 - accuracy: 0.9806 - val_loss: 1.0464 - val_accuracy: 0.8141\n",
      "Epoch 124/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.0765 - accuracy: 0.9751 - val_loss: 1.0563 - val_accuracy: 0.8141\n",
      "Epoch 125/150\n",
      "37/37 [==============================] - 0s 822us/step - loss: 0.0762 - accuracy: 0.9778 - val_loss: 1.0628 - val_accuracy: 0.8141\n",
      "Epoch 126/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.0732 - accuracy: 0.9806 - val_loss: 1.0775 - val_accuracy: 0.8077\n",
      "Epoch 127/150\n",
      "37/37 [==============================] - 0s 962us/step - loss: 0.0713 - accuracy: 0.9861 - val_loss: 1.0823 - val_accuracy: 0.8141\n",
      "Epoch 128/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.0706 - accuracy: 0.9778 - val_loss: 1.0883 - val_accuracy: 0.8077\n",
      "Epoch 129/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.0714 - accuracy: 0.9778 - val_loss: 1.0953 - val_accuracy: 0.8013\n",
      "Epoch 130/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.0696 - accuracy: 0.9917 - val_loss: 1.1106 - val_accuracy: 0.8077\n",
      "Epoch 131/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0712 - accuracy: 0.9778 - val_loss: 1.1158 - val_accuracy: 0.8205\n",
      "Epoch 132/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.0677 - accuracy: 0.9861 - val_loss: 1.1063 - val_accuracy: 0.8013\n",
      "Epoch 133/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.0654 - accuracy: 0.9834 - val_loss: 1.1347 - val_accuracy: 0.8205\n",
      "Epoch 134/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.0675 - accuracy: 0.9778 - val_loss: 1.1280 - val_accuracy: 0.8077\n",
      "Epoch 135/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.0648 - accuracy: 0.9861 - val_loss: 1.1500 - val_accuracy: 0.8141\n",
      "Epoch 136/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.0655 - accuracy: 0.9834 - val_loss: 1.1545 - val_accuracy: 0.8205\n",
      "Epoch 137/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.0656 - accuracy: 0.9861 - val_loss: 1.1542 - val_accuracy: 0.8205\n",
      "Epoch 138/150\n",
      "37/37 [==============================] - 0s 987us/step - loss: 0.0845 - accuracy: 0.9751 - val_loss: 1.1981 - val_accuracy: 0.8077\n",
      "Epoch 139/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.0649 - accuracy: 0.9778 - val_loss: 1.1543 - val_accuracy: 0.8077\n",
      "Epoch 140/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.0580 - accuracy: 0.9834 - val_loss: 1.1672 - val_accuracy: 0.8077\n",
      "Epoch 141/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.0572 - accuracy: 0.9861 - val_loss: 1.1807 - val_accuracy: 0.8077\n",
      "Epoch 142/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0567 - accuracy: 0.9806 - val_loss: 1.1969 - val_accuracy: 0.8013\n",
      "Epoch 143/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.0586 - accuracy: 0.9806 - val_loss: 1.2080 - val_accuracy: 0.8269\n",
      "Epoch 144/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.0563 - accuracy: 0.9889 - val_loss: 1.2073 - val_accuracy: 0.8141\n",
      "Epoch 145/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.0554 - accuracy: 0.9834 - val_loss: 1.2174 - val_accuracy: 0.8077\n",
      "Epoch 146/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.0537 - accuracy: 0.9917 - val_loss: 1.2202 - val_accuracy: 0.8141\n",
      "Epoch 147/150\n",
      "37/37 [==============================] - 0s 1ms/step - loss: 0.0527 - accuracy: 0.9834 - val_loss: 1.2284 - val_accuracy: 0.8141\n",
      "Epoch 148/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0536 - accuracy: 0.9834 - val_loss: 1.2351 - val_accuracy: 0.8141\n",
      "Epoch 149/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0507 - accuracy: 0.9945 - val_loss: 1.2501 - val_accuracy: 0.8205\n",
      "Epoch 150/150\n",
      "37/37 [==============================] - 0s 2ms/step - loss: 0.0506 - accuracy: 0.9861 - val_loss: 1.2509 - val_accuracy: 0.8141\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x23eecd335b0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, Y, validation_split=0.3, epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 873us/step - loss: 0.4094 - accuracy: 0.9400\n",
      "accuracy: 94.00%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X, Y)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network on Gas turbine dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import keras\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "turbine_data= pd.read_csv('gas_turbines.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= turbine_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AT</th>\n",
       "      <th>AP</th>\n",
       "      <th>AH</th>\n",
       "      <th>AFDP</th>\n",
       "      <th>GTEP</th>\n",
       "      <th>TIT</th>\n",
       "      <th>TAT</th>\n",
       "      <th>TEY</th>\n",
       "      <th>CDP</th>\n",
       "      <th>CO</th>\n",
       "      <th>NOX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.8594</td>\n",
       "      <td>1007.9</td>\n",
       "      <td>96.799</td>\n",
       "      <td>3.5000</td>\n",
       "      <td>19.663</td>\n",
       "      <td>1059.2</td>\n",
       "      <td>550.00</td>\n",
       "      <td>114.70</td>\n",
       "      <td>10.605</td>\n",
       "      <td>3.1547</td>\n",
       "      <td>82.722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.7850</td>\n",
       "      <td>1008.4</td>\n",
       "      <td>97.118</td>\n",
       "      <td>3.4998</td>\n",
       "      <td>19.728</td>\n",
       "      <td>1059.3</td>\n",
       "      <td>550.00</td>\n",
       "      <td>114.72</td>\n",
       "      <td>10.598</td>\n",
       "      <td>3.2363</td>\n",
       "      <td>82.776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.8977</td>\n",
       "      <td>1008.8</td>\n",
       "      <td>95.939</td>\n",
       "      <td>3.4824</td>\n",
       "      <td>19.779</td>\n",
       "      <td>1059.4</td>\n",
       "      <td>549.87</td>\n",
       "      <td>114.71</td>\n",
       "      <td>10.601</td>\n",
       "      <td>3.2012</td>\n",
       "      <td>82.468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.0569</td>\n",
       "      <td>1009.2</td>\n",
       "      <td>95.249</td>\n",
       "      <td>3.4805</td>\n",
       "      <td>19.792</td>\n",
       "      <td>1059.6</td>\n",
       "      <td>549.99</td>\n",
       "      <td>114.72</td>\n",
       "      <td>10.606</td>\n",
       "      <td>3.1923</td>\n",
       "      <td>82.670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.3978</td>\n",
       "      <td>1009.7</td>\n",
       "      <td>95.150</td>\n",
       "      <td>3.4976</td>\n",
       "      <td>19.765</td>\n",
       "      <td>1059.7</td>\n",
       "      <td>549.98</td>\n",
       "      <td>114.72</td>\n",
       "      <td>10.612</td>\n",
       "      <td>3.2484</td>\n",
       "      <td>82.311</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       AT      AP      AH    AFDP    GTEP     TIT     TAT     TEY     CDP  \\\n",
       "0  6.8594  1007.9  96.799  3.5000  19.663  1059.2  550.00  114.70  10.605   \n",
       "1  6.7850  1008.4  97.118  3.4998  19.728  1059.3  550.00  114.72  10.598   \n",
       "2  6.8977  1008.8  95.939  3.4824  19.779  1059.4  549.87  114.71  10.601   \n",
       "3  7.0569  1009.2  95.249  3.4805  19.792  1059.6  549.99  114.72  10.606   \n",
       "4  7.3978  1009.7  95.150  3.4976  19.765  1059.7  549.98  114.72  10.612   \n",
       "\n",
       "       CO     NOX  \n",
       "0  3.1547  82.722  \n",
       "1  3.2363  82.776  \n",
       "2  3.2012  82.468  \n",
       "3  3.1923  82.670  \n",
       "4  3.2484  82.311  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15039 entries, 0 to 15038\n",
      "Data columns (total 11 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   AT      15039 non-null  float64\n",
      " 1   AP      15039 non-null  float64\n",
      " 2   AH      15039 non-null  float64\n",
      " 3   AFDP    15039 non-null  float64\n",
      " 4   GTEP    15039 non-null  float64\n",
      " 5   TIT     15039 non-null  float64\n",
      " 6   TAT     15039 non-null  float64\n",
      " 7   TEY     15039 non-null  float64\n",
      " 8   CDP     15039 non-null  float64\n",
      " 9   CO      15039 non-null  float64\n",
      " 10  NOX     15039 non-null  float64\n",
      "dtypes: float64(11)\n",
      "memory usage: 1.3 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AT</th>\n",
       "      <th>AP</th>\n",
       "      <th>AH</th>\n",
       "      <th>AFDP</th>\n",
       "      <th>GTEP</th>\n",
       "      <th>TIT</th>\n",
       "      <th>TAT</th>\n",
       "      <th>TEY</th>\n",
       "      <th>CDP</th>\n",
       "      <th>CO</th>\n",
       "      <th>NOX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>15039.000000</td>\n",
       "      <td>15039.00000</td>\n",
       "      <td>15039.000000</td>\n",
       "      <td>15039.000000</td>\n",
       "      <td>15039.000000</td>\n",
       "      <td>15039.000000</td>\n",
       "      <td>15039.000000</td>\n",
       "      <td>15039.000000</td>\n",
       "      <td>15039.000000</td>\n",
       "      <td>15039.000000</td>\n",
       "      <td>15039.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>17.764381</td>\n",
       "      <td>1013.19924</td>\n",
       "      <td>79.124174</td>\n",
       "      <td>4.200294</td>\n",
       "      <td>25.419061</td>\n",
       "      <td>1083.798770</td>\n",
       "      <td>545.396183</td>\n",
       "      <td>134.188464</td>\n",
       "      <td>12.102353</td>\n",
       "      <td>1.972499</td>\n",
       "      <td>68.190934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.574323</td>\n",
       "      <td>6.41076</td>\n",
       "      <td>13.793439</td>\n",
       "      <td>0.760197</td>\n",
       "      <td>4.173916</td>\n",
       "      <td>16.527806</td>\n",
       "      <td>7.866803</td>\n",
       "      <td>15.829717</td>\n",
       "      <td>1.103196</td>\n",
       "      <td>2.222206</td>\n",
       "      <td>10.470586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.522300</td>\n",
       "      <td>985.85000</td>\n",
       "      <td>30.344000</td>\n",
       "      <td>2.087400</td>\n",
       "      <td>17.878000</td>\n",
       "      <td>1000.800000</td>\n",
       "      <td>512.450000</td>\n",
       "      <td>100.170000</td>\n",
       "      <td>9.904400</td>\n",
       "      <td>0.000388</td>\n",
       "      <td>27.765000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>11.408000</td>\n",
       "      <td>1008.90000</td>\n",
       "      <td>69.750000</td>\n",
       "      <td>3.723900</td>\n",
       "      <td>23.294000</td>\n",
       "      <td>1079.600000</td>\n",
       "      <td>542.170000</td>\n",
       "      <td>127.985000</td>\n",
       "      <td>11.622000</td>\n",
       "      <td>0.858055</td>\n",
       "      <td>61.303500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>18.186000</td>\n",
       "      <td>1012.80000</td>\n",
       "      <td>82.266000</td>\n",
       "      <td>4.186200</td>\n",
       "      <td>25.082000</td>\n",
       "      <td>1088.700000</td>\n",
       "      <td>549.890000</td>\n",
       "      <td>133.780000</td>\n",
       "      <td>12.025000</td>\n",
       "      <td>1.390200</td>\n",
       "      <td>66.601000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>23.862500</td>\n",
       "      <td>1016.90000</td>\n",
       "      <td>90.043500</td>\n",
       "      <td>4.550900</td>\n",
       "      <td>27.184000</td>\n",
       "      <td>1096.000000</td>\n",
       "      <td>550.060000</td>\n",
       "      <td>140.895000</td>\n",
       "      <td>12.578000</td>\n",
       "      <td>2.160400</td>\n",
       "      <td>73.935500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>34.929000</td>\n",
       "      <td>1034.20000</td>\n",
       "      <td>100.200000</td>\n",
       "      <td>7.610600</td>\n",
       "      <td>37.402000</td>\n",
       "      <td>1100.800000</td>\n",
       "      <td>550.610000</td>\n",
       "      <td>174.610000</td>\n",
       "      <td>15.081000</td>\n",
       "      <td>44.103000</td>\n",
       "      <td>119.890000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 AT           AP            AH          AFDP          GTEP  \\\n",
       "count  15039.000000  15039.00000  15039.000000  15039.000000  15039.000000   \n",
       "mean      17.764381   1013.19924     79.124174      4.200294     25.419061   \n",
       "std        7.574323      6.41076     13.793439      0.760197      4.173916   \n",
       "min        0.522300    985.85000     30.344000      2.087400     17.878000   \n",
       "25%       11.408000   1008.90000     69.750000      3.723900     23.294000   \n",
       "50%       18.186000   1012.80000     82.266000      4.186200     25.082000   \n",
       "75%       23.862500   1016.90000     90.043500      4.550900     27.184000   \n",
       "max       34.929000   1034.20000    100.200000      7.610600     37.402000   \n",
       "\n",
       "                TIT           TAT           TEY           CDP            CO  \\\n",
       "count  15039.000000  15039.000000  15039.000000  15039.000000  15039.000000   \n",
       "mean    1083.798770    545.396183    134.188464     12.102353      1.972499   \n",
       "std       16.527806      7.866803     15.829717      1.103196      2.222206   \n",
       "min     1000.800000    512.450000    100.170000      9.904400      0.000388   \n",
       "25%     1079.600000    542.170000    127.985000     11.622000      0.858055   \n",
       "50%     1088.700000    549.890000    133.780000     12.025000      1.390200   \n",
       "75%     1096.000000    550.060000    140.895000     12.578000      2.160400   \n",
       "max     1100.800000    550.610000    174.610000     15.081000     44.103000   \n",
       "\n",
       "                NOX  \n",
       "count  15039.000000  \n",
       "mean      68.190934  \n",
       "std       10.470586  \n",
       "min       27.765000  \n",
       "25%       61.303500  \n",
       "50%       66.601000  \n",
       "75%       73.935500  \n",
       "max      119.890000  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           AT      AP      AH    AFDP    GTEP     TIT     TAT     CDP      CO  \\\n",
      "0      6.8594  1007.9  96.799  3.5000  19.663  1059.2  550.00  10.605  3.1547   \n",
      "1      6.7850  1008.4  97.118  3.4998  19.728  1059.3  550.00  10.598  3.2363   \n",
      "2      6.8977  1008.8  95.939  3.4824  19.779  1059.4  549.87  10.601  3.2012   \n",
      "3      7.0569  1009.2  95.249  3.4805  19.792  1059.6  549.99  10.606  3.1923   \n",
      "4      7.3978  1009.7  95.150  3.4976  19.765  1059.7  549.98  10.612  3.2484   \n",
      "...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
      "15034  9.0301  1005.6  98.460  3.5421  19.164  1049.7  546.21  10.400  4.5186   \n",
      "15035  7.8879  1005.9  99.093  3.5059  19.414  1046.3  543.22  10.433  4.8470   \n",
      "15036  7.2647  1006.3  99.496  3.4770  19.530  1037.7  537.32  10.483  7.9632   \n",
      "15037  7.0060  1006.8  99.008  3.4486  19.377  1043.2  541.24  10.533  6.2494   \n",
      "15038  6.9279  1007.2  97.533  3.4275  19.306  1049.9  545.85  10.583  4.9816   \n",
      "\n",
      "          NOX  \n",
      "0      82.722  \n",
      "1      82.776  \n",
      "2      82.468  \n",
      "3      82.670  \n",
      "4      82.311  \n",
      "...       ...  \n",
      "15034  79.559  \n",
      "15035  79.917  \n",
      "15036  90.912  \n",
      "15037  93.227  \n",
      "15038  92.498  \n",
      "\n",
      "[15039 rows x 10 columns]\n",
      "0        114.70\n",
      "1        114.72\n",
      "2        114.71\n",
      "3        114.72\n",
      "4        114.72\n",
      "          ...  \n",
      "15034    111.61\n",
      "15035    111.78\n",
      "15036    110.19\n",
      "15037    110.74\n",
      "15038    111.58\n",
      "Name: TEY, Length: 15039, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "x= df[['AT', 'AP', 'AH', 'AFDP', 'GTEP', 'TIT', 'TAT', 'CDP', 'CO', 'NOX']]\n",
    "print(x)\n",
    "y= df['TEY']\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_standerdized= (x-x.mean())/x.std()\n",
    "x_standerdized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "  model= Sequential()\n",
    "  model.add(Dense(10, input_dim=10, kernel_initializer= 'normal', activation='relu'))\n",
    "  model.add(Dense(8, kernel_initializer= 'normal', activation='relu'))\n",
    "  model.add(Dense(8, kernel_initializer= 'normal', activation='relu'))\n",
    "  model.add(Dense(1, kernel_initializer= 'normal')) \n",
    "  adam= Adam()\n",
    "# Compile model\n",
    "  model.compile(loss='mean_squared_error', optimizer=adam)\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "[CV] batch_size=50, epochs=10 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ......... batch_size=50, epochs=10, score=-171.339, total=   2.9s\n",
      "[CV] batch_size=50, epochs=10 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    2.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .......... batch_size=50, epochs=10, score=-49.760, total=   2.7s\n",
      "[CV] batch_size=50, epochs=10 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    5.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .......... batch_size=50, epochs=10, score=-56.368, total=   2.3s\n",
      "[CV] batch_size=50, epochs=10 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    7.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .......... batch_size=50, epochs=10, score=-51.269, total=   2.3s\n",
      "[CV] batch_size=50, epochs=10 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   10.2s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .......... batch_size=50, epochs=10, score=-59.401, total=   2.2s\n",
      "[CV] batch_size=50, epochs=50 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   12.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........... batch_size=50, epochs=50, score=-0.920, total=   6.8s\n",
      "[CV] batch_size=50, epochs=50 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:   19.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........... batch_size=50, epochs=50, score=-0.433, total=   6.9s\n",
      "[CV] batch_size=50, epochs=50 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:   26.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........... batch_size=50, epochs=50, score=-0.799, total=   6.8s\n",
      "[CV] batch_size=50, epochs=50 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:   32.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........... batch_size=50, epochs=50, score=-0.544, total=   6.7s\n",
      "[CV] batch_size=50, epochs=50 ........................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:   39.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........... batch_size=50, epochs=50, score=-1.438, total=   6.6s\n",
      "[CV] batch_size=50, epochs=100 .......................................\n",
      "[CV] .......... batch_size=50, epochs=100, score=-0.755, total=  11.4s\n",
      "[CV] batch_size=50, epochs=100 .......................................\n",
      "[CV] .......... batch_size=50, epochs=100, score=-0.490, total=  12.2s\n",
      "[CV] batch_size=50, epochs=100 .......................................\n",
      "[CV] .......... batch_size=50, epochs=100, score=-0.591, total=  12.8s\n",
      "[CV] batch_size=50, epochs=100 .......................................\n",
      "[CV] .......... batch_size=50, epochs=100, score=-0.598, total=  12.8s\n",
      "[CV] batch_size=50, epochs=100 .......................................\n",
      "[CV] .......... batch_size=50, epochs=100, score=-0.718, total=  12.3s\n",
      "[CV] batch_size=100, epochs=10 .......................................\n",
      "[CV] ........ batch_size=100, epochs=10, score=-330.689, total=   1.6s\n",
      "[CV] batch_size=100, epochs=10 .......................................\n",
      "[CV] ........ batch_size=100, epochs=10, score=-354.373, total=   1.6s\n",
      "[CV] batch_size=100, epochs=10 .......................................\n",
      "[CV] ........ batch_size=100, epochs=10, score=-236.944, total=   2.0s\n",
      "[CV] batch_size=100, epochs=10 .......................................\n",
      "[CV] ........ batch_size=100, epochs=10, score=-178.512, total=   1.7s\n",
      "[CV] batch_size=100, epochs=10 .......................................\n",
      "[CV] ........ batch_size=100, epochs=10, score=-131.306, total=   1.7s\n",
      "[CV] batch_size=100, epochs=50 .......................................\n",
      "[CV] .......... batch_size=100, epochs=50, score=-2.869, total=   4.2s\n",
      "[CV] batch_size=100, epochs=50 .......................................\n",
      "[CV] .......... batch_size=100, epochs=50, score=-0.528, total=   4.8s\n",
      "[CV] batch_size=100, epochs=50 .......................................\n",
      "[CV] .......... batch_size=100, epochs=50, score=-1.629, total=   4.4s\n",
      "[CV] batch_size=100, epochs=50 .......................................\n",
      "[CV] .......... batch_size=100, epochs=50, score=-1.863, total=   4.1s\n",
      "[CV] batch_size=100, epochs=50 .......................................\n",
      "[CV] .......... batch_size=100, epochs=50, score=-2.636, total=   4.2s\n",
      "[CV] batch_size=100, epochs=100 ......................................\n",
      "[CV] ......... batch_size=100, epochs=100, score=-1.060, total=   6.8s\n",
      "[CV] batch_size=100, epochs=100 ......................................\n",
      "[CV] ......... batch_size=100, epochs=100, score=-0.447, total=   7.1s\n",
      "[CV] batch_size=100, epochs=100 ......................................\n",
      "[CV] ......... batch_size=100, epochs=100, score=-0.714, total=   8.0s\n",
      "[CV] batch_size=100, epochs=100 ......................................\n",
      "[CV] ......... batch_size=100, epochs=100, score=-0.509, total=   7.6s\n",
      "[CV] batch_size=100, epochs=100 ......................................\n",
      "[CV] ......... batch_size=100, epochs=100, score=-1.064, total=   7.4s\n",
      "[CV] batch_size=200, epochs=10 .......................................\n",
      "[CV] ........ batch_size=200, epochs=10, score=-745.929, total=   1.3s\n",
      "[CV] batch_size=200, epochs=10 .......................................\n",
      "[CV] ....... batch_size=200, epochs=10, score=-1106.307, total=   1.5s\n",
      "[CV] batch_size=200, epochs=10 .......................................\n",
      "[CV] ....... batch_size=200, epochs=10, score=-1170.520, total=   1.5s\n",
      "[CV] batch_size=200, epochs=10 .......................................\n",
      "[CV] ........ batch_size=200, epochs=10, score=-435.177, total=   1.4s\n",
      "[CV] batch_size=200, epochs=10 .......................................\n",
      "[CV] ........ batch_size=200, epochs=10, score=-587.633, total=   1.3s\n",
      "[CV] batch_size=200, epochs=50 .......................................\n",
      "[CV] ......... batch_size=200, epochs=50, score=-84.304, total=   2.6s\n",
      "[CV] batch_size=200, epochs=50 .......................................\n",
      "[CV] ......... batch_size=200, epochs=50, score=-25.636, total=   2.8s\n",
      "[CV] batch_size=200, epochs=50 .......................................\n",
      "[CV] ......... batch_size=200, epochs=50, score=-22.112, total=   2.6s\n",
      "[CV] batch_size=200, epochs=50 .......................................\n",
      "[CV] ......... batch_size=200, epochs=50, score=-55.785, total=   2.6s\n",
      "[CV] batch_size=200, epochs=50 .......................................\n",
      "[CV] ......... batch_size=200, epochs=50, score=-30.320, total=   2.5s\n",
      "[CV] batch_size=200, epochs=100 ......................................\n",
      "[CV] ......... batch_size=200, epochs=100, score=-3.870, total=   4.5s\n",
      "[CV] batch_size=200, epochs=100 ......................................\n",
      "[CV] ......... batch_size=200, epochs=100, score=-1.071, total=   4.4s\n",
      "[CV] batch_size=200, epochs=100 ......................................\n",
      "[CV] ......... batch_size=200, epochs=100, score=-0.754, total=   4.2s\n",
      "[CV] batch_size=200, epochs=100 ......................................\n",
      "[CV] ......... batch_size=200, epochs=100, score=-1.083, total=   4.4s\n",
      "[CV] batch_size=200, epochs=100 ......................................\n",
      "[CV] ......... batch_size=200, epochs=100, score=-1.976, total=   4.4s\n",
      "[CV] batch_size=400, epochs=10 .......................................\n",
      "[CV] ....... batch_size=400, epochs=10, score=-4916.329, total=   1.4s\n",
      "[CV] batch_size=400, epochs=10 .......................................\n",
      "[CV] ....... batch_size=400, epochs=10, score=-5489.864, total=   1.1s\n",
      "[CV] batch_size=400, epochs=10 .......................................\n",
      "[CV] ....... batch_size=400, epochs=10, score=-6713.979, total=   1.1s\n",
      "[CV] batch_size=400, epochs=10 .......................................\n",
      "[CV] ....... batch_size=400, epochs=10, score=-5925.340, total=   1.1s\n",
      "[CV] batch_size=400, epochs=10 .......................................\n",
      "[CV] ....... batch_size=400, epochs=10, score=-3243.866, total=   1.1s\n",
      "[CV] batch_size=400, epochs=50 .......................................\n",
      "[CV] ........ batch_size=400, epochs=50, score=-262.953, total=   2.0s\n",
      "[CV] batch_size=400, epochs=50 .......................................\n",
      "[CV] ........ batch_size=400, epochs=50, score=-183.300, total=   1.8s\n",
      "[CV] batch_size=400, epochs=50 .......................................\n",
      "[CV] ........ batch_size=400, epochs=50, score=-139.565, total=   1.8s\n",
      "[CV] batch_size=400, epochs=50 .......................................\n",
      "[CV] ........ batch_size=400, epochs=50, score=-129.867, total=   1.9s\n",
      "[CV] batch_size=400, epochs=50 .......................................\n",
      "[CV] ........ batch_size=400, epochs=50, score=-122.990, total=   2.0s\n",
      "[CV] batch_size=400, epochs=100 ......................................\n",
      "[CV] ........ batch_size=400, epochs=100, score=-40.771, total=   2.8s\n",
      "[CV] batch_size=400, epochs=100 ......................................\n",
      "[CV] ........ batch_size=400, epochs=100, score=-13.156, total=   2.8s\n",
      "[CV] batch_size=400, epochs=100 ......................................\n",
      "[CV] ........ batch_size=400, epochs=100, score=-21.279, total=   2.8s\n",
      "[CV] batch_size=400, epochs=100 ......................................\n",
      "[CV] ........ batch_size=400, epochs=100, score=-10.089, total=   2.8s\n",
      "[CV] batch_size=400, epochs=100 ......................................\n",
      "[CV] ........ batch_size=400, epochs=100, score=-19.837, total=   3.0s\n",
      "[CV] batch_size=800, epochs=10 .......................................\n",
      "[CV] ...... batch_size=800, epochs=10, score=-16945.338, total=   1.0s\n",
      "[CV] batch_size=800, epochs=10 .......................................\n",
      "[CV] ...... batch_size=800, epochs=10, score=-16111.466, total=   1.0s\n",
      "[CV] batch_size=800, epochs=10 .......................................\n",
      "[CV] ...... batch_size=800, epochs=10, score=-19113.498, total=   1.0s\n",
      "[CV] batch_size=800, epochs=10 .......................................\n",
      "[CV] ...... batch_size=800, epochs=10, score=-17032.107, total=   1.0s\n",
      "[CV] batch_size=800, epochs=10 .......................................\n",
      "[CV] ...... batch_size=800, epochs=10, score=-16171.552, total=   1.2s\n",
      "[CV] batch_size=800, epochs=50 .......................................\n",
      "[CV] ........ batch_size=800, epochs=50, score=-492.676, total=   1.5s\n",
      "[CV] batch_size=800, epochs=50 .......................................\n",
      "[CV] ........ batch_size=800, epochs=50, score=-467.091, total=   1.5s\n",
      "[CV] batch_size=800, epochs=50 .......................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........ batch_size=800, epochs=50, score=-715.222, total=   1.5s\n",
      "[CV] batch_size=800, epochs=50 .......................................\n",
      "[CV] ........ batch_size=800, epochs=50, score=-310.240, total=   1.5s\n",
      "[CV] batch_size=800, epochs=50 .......................................\n",
      "[CV] ........ batch_size=800, epochs=50, score=-291.119, total=   1.8s\n",
      "[CV] batch_size=800, epochs=100 ......................................\n",
      "[CV] ....... batch_size=800, epochs=100, score=-242.878, total=   2.0s\n",
      "[CV] batch_size=800, epochs=100 ......................................\n",
      "[CV] ........ batch_size=800, epochs=100, score=-50.254, total=   2.0s\n",
      "[CV] batch_size=800, epochs=100 ......................................\n",
      "[CV] ....... batch_size=800, epochs=100, score=-123.117, total=   2.1s\n",
      "[CV] batch_size=800, epochs=100 ......................................\n",
      "[CV] ........ batch_size=800, epochs=100, score=-98.211, total=   2.2s\n",
      "[CV] batch_size=800, epochs=100 ......................................\n",
      "[CV] ........ batch_size=800, epochs=100, score=-83.664, total=   2.1s\n",
      "[CV] batch_size=1000, epochs=10 ......................................\n",
      "[CV] ..... batch_size=1000, epochs=10, score=-18243.902, total=   1.0s\n",
      "[CV] batch_size=1000, epochs=10 ......................................\n",
      "[CV] ..... batch_size=1000, epochs=10, score=-16700.273, total=   1.0s\n",
      "[CV] batch_size=1000, epochs=10 ......................................\n",
      "[CV] ..... batch_size=1000, epochs=10, score=-19072.469, total=   1.0s\n",
      "[CV] batch_size=1000, epochs=10 ......................................\n",
      "[CV] ..... batch_size=1000, epochs=10, score=-18011.082, total=   1.1s\n",
      "[CV] batch_size=1000, epochs=10 ......................................\n",
      "[CV] ..... batch_size=1000, epochs=10, score=-17240.740, total=   1.0s\n",
      "[CV] batch_size=1000, epochs=50 ......................................\n",
      "[CV] ....... batch_size=1000, epochs=50, score=-718.158, total=   1.4s\n",
      "[CV] batch_size=1000, epochs=50 ......................................\n",
      "[CV] ....... batch_size=1000, epochs=50, score=-601.090, total=   1.4s\n",
      "[CV] batch_size=1000, epochs=50 ......................................\n",
      "[CV] ....... batch_size=1000, epochs=50, score=-578.428, total=   1.5s\n",
      "[CV] batch_size=1000, epochs=50 ......................................\n",
      "[CV] ....... batch_size=1000, epochs=50, score=-441.968, total=   1.4s\n",
      "[CV] batch_size=1000, epochs=50 ......................................\n",
      "[CV] ....... batch_size=1000, epochs=50, score=-333.886, total=   1.4s\n",
      "[CV] batch_size=1000, epochs=100 .....................................\n",
      "[CV] ...... batch_size=1000, epochs=100, score=-268.969, total=   1.8s\n",
      "[CV] batch_size=1000, epochs=100 .....................................\n",
      "[CV] ...... batch_size=1000, epochs=100, score=-271.690, total=   1.8s\n",
      "[CV] batch_size=1000, epochs=100 .....................................\n",
      "[CV] ...... batch_size=1000, epochs=100, score=-179.842, total=   2.1s\n",
      "[CV] batch_size=1000, epochs=100 .....................................\n",
      "[CV] ...... batch_size=1000, epochs=100, score=-124.333, total=   1.9s\n",
      "[CV] batch_size=1000, epochs=100 .....................................\n",
      "[CV] ...... batch_size=1000, epochs=100, score=-118.210, total=   1.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  90 out of  90 | elapsed:  4.9min finished\n"
     ]
    }
   ],
   "source": [
    "# create regression model\n",
    "model= KerasRegressor(build_fn=create_model, verbose=0)\n",
    "# create grid search model\n",
    "batch_size=[50,100, 200, 400, 800, 1000]\n",
    "epochs=[10,50,100]\n",
    "# Make a dictionary of grid search parameters\n",
    "param_grid= dict(batch_size= batch_size, epochs=epochs)\n",
    "#build and fit the gridsearchCV\n",
    "grid= GridSearchCV(estimator=model, param_grid=param_grid, cv= KFold(), verbose=10 )\n",
    "grid_result= grid.fit(x_standerdized,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best:-0.6303272604942322, using {'batch_size': 50, 'epochs': 100}\n",
      "-77.62733306884766,46.984039083674 with: {'batch_size': 50, 'epochs': 10}\n",
      "-0.8265738427639008,0.3517648556035991 with: {'batch_size': 50, 'epochs': 50}\n",
      "-0.6303272604942322,0.09550140289115999 with: {'batch_size': 50, 'epochs': 100}\n",
      "-246.36460876464844,85.68278271122355 with: {'batch_size': 100, 'epochs': 10}\n",
      "-1.9049873352050781,0.8293758215251685 with: {'batch_size': 100, 'epochs': 50}\n",
      "-0.7589312374591828,0.2628912574032711 with: {'batch_size': 100, 'epochs': 100}\n",
      "-809.11298828125,286.9889285971013 with: {'batch_size': 200, 'epochs': 10}\n",
      "-43.63120651245117,23.520566477048458 with: {'batch_size': 200, 'epochs': 50}\n",
      "-1.7506044507026672,1.1352879201211958 with: {'batch_size': 200, 'epochs': 100}\n",
      "-5257.875390625,1165.543093186542 with: {'batch_size': 400, 'epochs': 10}\n",
      "-167.7348892211914,52.03553357914714 with: {'batch_size': 400, 'epochs': 50}\n",
      "-21.02638473510742,10.704417054823564 with: {'batch_size': 400, 'epochs': 100}\n",
      "-17074.7921875,1088.0021092614245 with: {'batch_size': 800, 'epochs': 10}\n",
      "-455.2696044921875,153.03150864972105 with: {'batch_size': 800, 'epochs': 50}\n",
      "-119.62476043701172,65.98111199957133 with: {'batch_size': 800, 'epochs': 100}\n",
      "-17853.693359375,820.7967772768194 with: {'batch_size': 1000, 'epochs': 10}\n",
      "-534.7061767578125,133.34333922398972 with: {'batch_size': 1000, 'epochs': 50}\n",
      "-192.60890502929686,66.99914964655522 with: {'batch_size': 1000, 'epochs': 100}\n"
     ]
    }
   ],
   "source": [
    "# summerize results\n",
    "print('Best:{}, using {}'.format(grid_result.best_score_, grid_result.best_params_))\n",
    "means= grid_result.cv_results_['mean_test_score']\n",
    "stds= grid_result.cv_results_['std_test_score']\n",
    "params= grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "  print('{},{} with: {}'.format(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n",
      "[CV] dropout_rate=0, learning_rate=0.001 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  dropout_rate=0, learning_rate=0.001, score=-0.880, total=   7.4s\n",
      "[CV] dropout_rate=0, learning_rate=0.001 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    7.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  dropout_rate=0, learning_rate=0.001, score=-0.400, total=   6.7s\n",
      "[CV] dropout_rate=0, learning_rate=0.001 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   14.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  dropout_rate=0, learning_rate=0.001, score=-1.144, total=   6.8s\n",
      "[CV] dropout_rate=0, learning_rate=0.001 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   20.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  dropout_rate=0, learning_rate=0.001, score=-0.472, total=   7.5s\n",
      "[CV] dropout_rate=0, learning_rate=0.001 .............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   28.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  dropout_rate=0, learning_rate=0.001, score=-0.819, total=   6.8s\n",
      "[CV] dropout_rate=0, learning_rate=0.01 ..............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   35.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . dropout_rate=0, learning_rate=0.01, score=-2.539, total=   7.7s\n",
      "[CV] dropout_rate=0, learning_rate=0.01 ..............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:   42.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . dropout_rate=0, learning_rate=0.01, score=-0.661, total=   6.9s\n",
      "[CV] dropout_rate=0, learning_rate=0.01 ..............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:   49.6s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . dropout_rate=0, learning_rate=0.01, score=-0.787, total=   6.3s\n",
      "[CV] dropout_rate=0, learning_rate=0.01 ..............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:   55.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . dropout_rate=0, learning_rate=0.01, score=-0.524, total=   7.6s\n",
      "[CV] dropout_rate=0, learning_rate=0.01 ..............................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:  1.1min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] . dropout_rate=0, learning_rate=0.01, score=-0.891, total=   7.6s\n",
      "[CV] dropout_rate=0, learning_rate=0.1 ...............................\n",
      "[CV] .. dropout_rate=0, learning_rate=0.1, score=-2.996, total=   7.5s\n",
      "[CV] dropout_rate=0, learning_rate=0.1 ...............................\n",
      "[CV] .. dropout_rate=0, learning_rate=0.1, score=-0.970, total=   7.9s\n",
      "[CV] dropout_rate=0, learning_rate=0.1 ...............................\n",
      "[CV] .. dropout_rate=0, learning_rate=0.1, score=-1.538, total=   7.2s\n",
      "[CV] dropout_rate=0, learning_rate=0.1 ...............................\n",
      "[CV] .. dropout_rate=0, learning_rate=0.1, score=-2.350, total=   7.7s\n",
      "[CV] dropout_rate=0, learning_rate=0.1 ...............................\n",
      "[CV] .. dropout_rate=0, learning_rate=0.1, score=-0.726, total=   6.4s\n",
      "[CV] dropout_rate=0, learning_rate=0.2 ...............................\n",
      "[CV] .. dropout_rate=0, learning_rate=0.2, score=-2.178, total=   7.6s\n",
      "[CV] dropout_rate=0, learning_rate=0.2 ...............................\n",
      "[CV] .. dropout_rate=0, learning_rate=0.2, score=-1.587, total=   7.5s\n",
      "[CV] dropout_rate=0, learning_rate=0.2 ...............................\n",
      "[CV] .. dropout_rate=0, learning_rate=0.2, score=-1.641, total=   6.8s\n",
      "[CV] dropout_rate=0, learning_rate=0.2 ...............................\n",
      "[CV] .. dropout_rate=0, learning_rate=0.2, score=-0.502, total=   7.4s\n",
      "[CV] dropout_rate=0, learning_rate=0.2 ...............................\n",
      "[CV] .. dropout_rate=0, learning_rate=0.2, score=-1.679, total=   7.5s\n",
      "[CV] dropout_rate=0, learning_rate=0.5 ...............................\n",
      "[CV] . dropout_rate=0, learning_rate=0.5, score=-14.263, total=   6.8s\n",
      "[CV] dropout_rate=0, learning_rate=0.5 ...............................\n",
      "[CV] .. dropout_rate=0, learning_rate=0.5, score=-1.836, total=   6.9s\n",
      "[CV] dropout_rate=0, learning_rate=0.5 ...............................\n",
      "[CV] .. dropout_rate=0, learning_rate=0.5, score=-1.230, total=   7.1s\n",
      "[CV] dropout_rate=0, learning_rate=0.5 ...............................\n",
      "[CV] .. dropout_rate=0, learning_rate=0.5, score=-1.123, total=   7.1s\n",
      "[CV] dropout_rate=0, learning_rate=0.5 ...............................\n",
      "[CV] . dropout_rate=0, learning_rate=0.5, score=-12.436, total=   7.7s\n",
      "[CV] dropout_rate=0.1, learning_rate=0.001 ...........................\n",
      "[CV]  dropout_rate=0.1, learning_rate=0.001, score=-11.903, total=   8.4s\n",
      "[CV] dropout_rate=0.1, learning_rate=0.001 ...........................\n",
      "[CV]  dropout_rate=0.1, learning_rate=0.001, score=-10.520, total=   8.1s\n",
      "[CV] dropout_rate=0.1, learning_rate=0.001 ...........................\n",
      "[CV]  dropout_rate=0.1, learning_rate=0.001, score=-14.881, total=   7.8s\n",
      "[CV] dropout_rate=0.1, learning_rate=0.001 ...........................\n",
      "[CV]  dropout_rate=0.1, learning_rate=0.001, score=-15.998, total=   8.5s\n",
      "[CV] dropout_rate=0.1, learning_rate=0.001 ...........................\n",
      "[CV]  dropout_rate=0.1, learning_rate=0.001, score=-10.058, total=   8.4s\n",
      "[CV] dropout_rate=0.1, learning_rate=0.01 ............................\n",
      "[CV]  dropout_rate=0.1, learning_rate=0.01, score=-15.530, total=   8.2s\n",
      "[CV] dropout_rate=0.1, learning_rate=0.01 ............................\n",
      "[CV]  dropout_rate=0.1, learning_rate=0.01, score=-3.718, total=   8.9s\n",
      "[CV] dropout_rate=0.1, learning_rate=0.01 ............................\n",
      "[CV]  dropout_rate=0.1, learning_rate=0.01, score=-1.992, total=   8.3s\n",
      "[CV] dropout_rate=0.1, learning_rate=0.01 ............................\n",
      "[CV]  dropout_rate=0.1, learning_rate=0.01, score=-4.860, total=   8.3s\n",
      "[CV] dropout_rate=0.1, learning_rate=0.01 ............................\n",
      "[CV]  dropout_rate=0.1, learning_rate=0.01, score=-3.921, total=   8.6s\n",
      "[CV] dropout_rate=0.1, learning_rate=0.1 .............................\n",
      "[CV]  dropout_rate=0.1, learning_rate=0.1, score=-24.556, total=   7.6s\n",
      "[CV] dropout_rate=0.1, learning_rate=0.1 .............................\n",
      "[CV]  dropout_rate=0.1, learning_rate=0.1, score=-7.571, total=   8.2s\n",
      "[CV] dropout_rate=0.1, learning_rate=0.1 .............................\n",
      "[CV]  dropout_rate=0.1, learning_rate=0.1, score=-19.897, total=   8.4s\n",
      "[CV] dropout_rate=0.1, learning_rate=0.1 .............................\n",
      "[CV]  dropout_rate=0.1, learning_rate=0.1, score=-11.661, total=   8.7s\n",
      "[CV] dropout_rate=0.1, learning_rate=0.1 .............................\n",
      "[CV]  dropout_rate=0.1, learning_rate=0.1, score=-23.316, total=   8.2s\n",
      "[CV] dropout_rate=0.1, learning_rate=0.2 .............................\n",
      "[CV]  dropout_rate=0.1, learning_rate=0.2, score=-40.465, total=   8.9s\n",
      "[CV] dropout_rate=0.1, learning_rate=0.2 .............................\n",
      "[CV]  dropout_rate=0.1, learning_rate=0.2, score=-86.124, total=   8.2s\n",
      "[CV] dropout_rate=0.1, learning_rate=0.2 .............................\n",
      "[CV]  dropout_rate=0.1, learning_rate=0.2, score=-10.103, total=   8.3s\n",
      "[CV] dropout_rate=0.1, learning_rate=0.2 .............................\n",
      "[CV]  dropout_rate=0.1, learning_rate=0.2, score=-10.298, total=   8.3s\n",
      "[CV] dropout_rate=0.1, learning_rate=0.2 .............................\n",
      "[CV]  dropout_rate=0.1, learning_rate=0.2, score=-18.889, total=   8.4s\n",
      "[CV] dropout_rate=0.1, learning_rate=0.5 .............................\n",
      "[CV]  dropout_rate=0.1, learning_rate=0.5, score=-119.297, total=   8.3s\n",
      "[CV] dropout_rate=0.1, learning_rate=0.5 .............................\n",
      "[CV]  dropout_rate=0.1, learning_rate=0.5, score=-120.013, total=   8.1s\n",
      "[CV] dropout_rate=0.1, learning_rate=0.5 .............................\n",
      "[CV]  dropout_rate=0.1, learning_rate=0.5, score=-307.635, total=   8.2s\n",
      "[CV] dropout_rate=0.1, learning_rate=0.5 .............................\n",
      "[CV]  dropout_rate=0.1, learning_rate=0.5, score=-15.518, total=   8.5s\n",
      "[CV] dropout_rate=0.1, learning_rate=0.5 .............................\n",
      "[CV]  dropout_rate=0.1, learning_rate=0.5, score=-261.785, total=   8.1s\n",
      "[CV] dropout_rate=0.2, learning_rate=0.001 ...........................\n",
      "[CV]  dropout_rate=0.2, learning_rate=0.001, score=-21.181, total=   8.3s\n",
      "[CV] dropout_rate=0.2, learning_rate=0.001 ...........................\n",
      "[CV]  dropout_rate=0.2, learning_rate=0.001, score=-37.390, total=   8.3s\n",
      "[CV] dropout_rate=0.2, learning_rate=0.001 ...........................\n",
      "[CV]  dropout_rate=0.2, learning_rate=0.001, score=-41.027, total=   8.2s\n",
      "[CV] dropout_rate=0.2, learning_rate=0.001 ...........................\n",
      "[CV]  dropout_rate=0.2, learning_rate=0.001, score=-42.815, total=   8.6s\n",
      "[CV] dropout_rate=0.2, learning_rate=0.001 ...........................\n",
      "[CV]  dropout_rate=0.2, learning_rate=0.001, score=-17.621, total=   8.8s\n",
      "[CV] dropout_rate=0.2, learning_rate=0.01 ............................\n",
      "[CV]  dropout_rate=0.2, learning_rate=0.01, score=-13.845, total=   9.0s\n",
      "[CV] dropout_rate=0.2, learning_rate=0.01 ............................\n",
      "[CV]  dropout_rate=0.2, learning_rate=0.01, score=-6.488, total=   9.8s\n",
      "[CV] dropout_rate=0.2, learning_rate=0.01 ............................\n",
      "[CV]  dropout_rate=0.2, learning_rate=0.01, score=-39.244, total=  10.0s\n",
      "[CV] dropout_rate=0.2, learning_rate=0.01 ............................\n",
      "[CV]  dropout_rate=0.2, learning_rate=0.01, score=-20.276, total=   9.8s\n",
      "[CV] dropout_rate=0.2, learning_rate=0.01 ............................\n",
      "[CV]  dropout_rate=0.2, learning_rate=0.01, score=-16.926, total=  11.5s\n",
      "[CV] dropout_rate=0.2, learning_rate=0.1 .............................\n",
      "[CV]  dropout_rate=0.2, learning_rate=0.1, score=-52.006, total=  10.2s\n",
      "[CV] dropout_rate=0.2, learning_rate=0.1 .............................\n",
      "[CV]  dropout_rate=0.2, learning_rate=0.1, score=-16.397, total=   8.8s\n",
      "[CV] dropout_rate=0.2, learning_rate=0.1 .............................\n",
      "[CV]  dropout_rate=0.2, learning_rate=0.1, score=-24.625, total=  11.4s\n",
      "[CV] dropout_rate=0.2, learning_rate=0.1 .............................\n",
      "[CV]  dropout_rate=0.2, learning_rate=0.1, score=-37.507, total=   8.6s\n",
      "[CV] dropout_rate=0.2, learning_rate=0.1 .............................\n",
      "[CV]  dropout_rate=0.2, learning_rate=0.1, score=-51.396, total=   8.1s\n",
      "[CV] dropout_rate=0.2, learning_rate=0.2 .............................\n",
      "[CV]  dropout_rate=0.2, learning_rate=0.2, score=-340.578, total=   8.5s\n",
      "[CV] dropout_rate=0.2, learning_rate=0.2 .............................\n",
      "[CV]  dropout_rate=0.2, learning_rate=0.2, score=-26.281, total=   8.0s\n",
      "[CV] dropout_rate=0.2, learning_rate=0.2 .............................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  dropout_rate=0.2, learning_rate=0.2, score=-62.611, total=   8.2s\n",
      "[CV] dropout_rate=0.2, learning_rate=0.2 .............................\n",
      "[CV]  dropout_rate=0.2, learning_rate=0.2, score=-32.955, total=   8.6s\n",
      "[CV] dropout_rate=0.2, learning_rate=0.2 .............................\n",
      "[CV]  dropout_rate=0.2, learning_rate=0.2, score=-59.758, total=   8.4s\n",
      "[CV] dropout_rate=0.2, learning_rate=0.5 .............................\n",
      "[CV]  dropout_rate=0.2, learning_rate=0.5, score=-344.787, total=   8.3s\n",
      "[CV] dropout_rate=0.2, learning_rate=0.5 .............................\n",
      "[CV]  dropout_rate=0.2, learning_rate=0.5, score=-87.068, total=   8.9s\n",
      "[CV] dropout_rate=0.2, learning_rate=0.5 .............................\n",
      "[CV]  dropout_rate=0.2, learning_rate=0.5, score=-318.975, total=   8.5s\n",
      "[CV] dropout_rate=0.2, learning_rate=0.5 .............................\n",
      "[CV]  dropout_rate=0.2, learning_rate=0.5, score=-236.235, total=   8.1s\n",
      "[CV] dropout_rate=0.2, learning_rate=0.5 .............................\n",
      "[CV]  dropout_rate=0.2, learning_rate=0.5, score=-260.110, total=   8.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  75 out of  75 | elapsed: 10.2min finished\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dropout\n",
    "\n",
    "# defining model\n",
    "def create_model_lr_drate(learning_rate,dropout_rate):\n",
    "  model= Sequential()\n",
    "  model.add(Dense(10, input_dim=10, kernel_initializer= 'normal', activation='relu'))\n",
    "  model.add(Dropout(dropout_rate))\n",
    "  model.add(Dense(8, kernel_initializer= 'normal', activation='relu'))\n",
    "  model.add(Dropout(dropout_rate))\n",
    "  model.add(Dense(8, kernel_initializer= 'normal', activation='relu'))\n",
    "  model.add(Dropout(dropout_rate))\n",
    "  model.add(Dense(1, kernel_initializer= 'normal')) \n",
    "  adam= Adam(learning_rate= learning_rate)\n",
    "# Compile model\n",
    "  model.compile(loss='mean_squared_error', optimizer=adam)\n",
    "  return model\n",
    "\n",
    "# Define regression model\n",
    "model= KerasRegressor(build_fn=create_model_lr_drate, verbose=0, batch_size=100, epochs=100)\n",
    "# Define grid search model\n",
    "learning_rate=[0.001, 0.01, 0.1, 0.2, 0.5]\n",
    "dropout_rate=[0, 0.1, 0.2]\n",
    "# Make a dictionary of grid search parameters\n",
    "param_grid= dict(learning_rate= learning_rate, dropout_rate=dropout_rate)\n",
    "#build and fit the gridsearchCV\n",
    "grid= GridSearchCV(estimator=model, param_grid=param_grid, cv= KFold(), verbose=10 )\n",
    "grid_result= grid.fit(x_standerdized,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best:-0.7430060386657715, using {'dropout_rate': 0, 'learning_rate': 0.001}\n",
      "-0.7430060386657715,0.27457883643385017 with: {'dropout_rate': 0, 'learning_rate': 0.001}\n",
      "-1.0807079434394837,0.7395768650965056 with: {'dropout_rate': 0, 'learning_rate': 0.01}\n",
      "-1.7159300327301026,0.8495368800904567 with: {'dropout_rate': 0, 'learning_rate': 0.1}\n",
      "-1.5173593759536743,0.5501555371238772 with: {'dropout_rate': 0, 'learning_rate': 0.2}\n",
      "-6.177544784545899,5.889242604070235 with: {'dropout_rate': 0, 'learning_rate': 0.5}\n",
      "-12.672068786621093,2.366218922267634 with: {'dropout_rate': 0.1, 'learning_rate': 0.001}\n",
      "-6.004189896583557,4.852163476374612 with: {'dropout_rate': 0.1, 'learning_rate': 0.01}\n",
      "-17.40024757385254,6.662949866034524 with: {'dropout_rate': 0.1, 'learning_rate': 0.1}\n",
      "-33.17603530883789,28.693275867277876 with: {'dropout_rate': 0.1, 'learning_rate': 0.2}\n",
      "-164.84982299804688,105.9901643111797 with: {'dropout_rate': 0.1, 'learning_rate': 0.5}\n",
      "-32.00689849853516,10.50052212560291 with: {'dropout_rate': 0.2, 'learning_rate': 0.001}\n",
      "-19.355908393859863,10.938283154280517 with: {'dropout_rate': 0.2, 'learning_rate': 0.01}\n",
      "-36.386200714111325,14.201747016573 with: {'dropout_rate': 0.2, 'learning_rate': 0.1}\n",
      "-104.43658180236817,118.93401912790573 with: {'dropout_rate': 0.2, 'learning_rate': 0.2}\n",
      "-249.43514709472657,90.08761667726026 with: {'dropout_rate': 0.2, 'learning_rate': 0.5}\n"
     ]
    }
   ],
   "source": [
    "print('Best:{}, using {}'.format(grid_result.best_score_, grid_result.best_params_))\n",
    "means= grid_result.cv_results_['mean_test_score']\n",
    "stds= grid_result.cv_results_['std_test_score']\n",
    "params= grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "  print('{},{} with: {}'.format(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
      "[CV] activation_function=linear, init=uniform ........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=linear, init=uniform, score=-0.754, total=   7.4s\n",
      "[CV] activation_function=linear, init=uniform ........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    7.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=linear, init=uniform, score=-0.435, total=   7.0s\n",
      "[CV] activation_function=linear, init=uniform ........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   14.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=linear, init=uniform, score=-0.838, total=   7.5s\n",
      "[CV] activation_function=linear, init=uniform ........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   21.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=linear, init=uniform, score=-0.424, total=   7.6s\n",
      "[CV] activation_function=linear, init=uniform ........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   29.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=linear, init=uniform, score=-0.585, total=   7.0s\n",
      "[CV] activation_function=linear, init=normal .........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   36.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=linear, init=normal, score=-0.790, total=   7.4s\n",
      "[CV] activation_function=linear, init=normal .........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:   43.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=linear, init=normal, score=-0.463, total=   7.5s\n",
      "[CV] activation_function=linear, init=normal .........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:   51.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=linear, init=normal, score=-0.713, total=   6.6s\n",
      "[CV] activation_function=linear, init=normal .........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:   57.9s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=linear, init=normal, score=-0.523, total=   6.4s\n",
      "[CV] activation_function=linear, init=normal .........................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:  1.1min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  activation_function=linear, init=normal, score=-0.649, total=   6.7s\n",
      "[CV] activation_function=linear, init=zero ...........................\n",
      "[CV]  activation_function=linear, init=zero, score=-15681.713, total=   6.8s\n",
      "[CV] activation_function=linear, init=zero ...........................\n",
      "[CV]  activation_function=linear, init=zero, score=-13996.440, total=   7.3s\n",
      "[CV] activation_function=linear, init=zero ...........................\n",
      "[CV]  activation_function=linear, init=zero, score=-16285.141, total=   7.4s\n",
      "[CV] activation_function=linear, init=zero ...........................\n",
      "[CV]  activation_function=linear, init=zero, score=-15403.896, total=   6.9s\n",
      "[CV] activation_function=linear, init=zero ...........................\n",
      "[CV]  activation_function=linear, init=zero, score=-14512.562, total=   7.5s\n",
      "[CV] activation_function=relu, init=uniform ..........................\n",
      "[CV]  activation_function=relu, init=uniform, score=-0.939, total=   7.5s\n",
      "[CV] activation_function=relu, init=uniform ..........................\n",
      "[CV]  activation_function=relu, init=uniform, score=-0.489, total=   7.7s\n",
      "[CV] activation_function=relu, init=uniform ..........................\n",
      "[CV]  activation_function=relu, init=uniform, score=-0.695, total=   6.9s\n",
      "[CV] activation_function=relu, init=uniform ..........................\n",
      "[CV]  activation_function=relu, init=uniform, score=-0.523, total=   7.2s\n",
      "[CV] activation_function=relu, init=uniform ..........................\n",
      "[CV]  activation_function=relu, init=uniform, score=-0.863, total=   7.2s\n",
      "[CV] activation_function=relu, init=normal ...........................\n",
      "[CV]  activation_function=relu, init=normal, score=-0.731, total=   7.5s\n",
      "[CV] activation_function=relu, init=normal ...........................\n",
      "[CV]  activation_function=relu, init=normal, score=-0.410, total=   7.2s\n",
      "[CV] activation_function=relu, init=normal ...........................\n",
      "[CV]  activation_function=relu, init=normal, score=-0.743, total=   7.2s\n",
      "[CV] activation_function=relu, init=normal ...........................\n",
      "[CV]  activation_function=relu, init=normal, score=-0.542, total=   6.9s\n",
      "[CV] activation_function=relu, init=normal ...........................\n",
      "[CV]  activation_function=relu, init=normal, score=-1.004, total=   7.2s\n",
      "[CV] activation_function=relu, init=zero .............................\n",
      "[CV]  activation_function=relu, init=zero, score=-15681.663, total=   7.8s\n",
      "[CV] activation_function=relu, init=zero .............................\n",
      "[CV]  activation_function=relu, init=zero, score=-13996.412, total=   7.6s\n",
      "[CV] activation_function=relu, init=zero .............................\n",
      "[CV]  activation_function=relu, init=zero, score=-16285.100, total=   7.5s\n",
      "[CV] activation_function=relu, init=zero .............................\n",
      "[CV]  activation_function=relu, init=zero, score=-15403.883, total=   7.5s\n",
      "[CV] activation_function=relu, init=zero .............................\n",
      "[CV]  activation_function=relu, init=zero, score=-14512.587, total=   7.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:  3.6min finished\n"
     ]
    }
   ],
   "source": [
    "def create_model_af_ker_ini(activation_function,init):\n",
    "  model= Sequential()\n",
    "  model.add(Dense(10, input_dim=10, kernel_initializer= init, activation=activation_function))\n",
    "  model.add(Dropout(0))\n",
    "  model.add(Dense(8, kernel_initializer= init, activation=activation_function))\n",
    "  model.add(Dropout(0))\n",
    "  model.add(Dense(8, kernel_initializer= init, activation=activation_function))\n",
    "  model.add(Dropout(0))\n",
    "  model.add(Dense(1, kernel_initializer= init, activation='linear')) \n",
    "  adam= Adam(learning_rate= 0.001)\n",
    "# Compile model\n",
    "  model.compile(loss='mean_squared_error', optimizer=adam)\n",
    "  return model\n",
    "\n",
    "# Define regression model\n",
    "model= KerasRegressor(build_fn=create_model_af_ker_ini, verbose=0, batch_size=100, epochs=100)\n",
    "# Define grid search model\n",
    "activation_function=['linear', 'relu']\n",
    "init=['uniform', 'normal', 'zero']\n",
    "# Make a dictionary of grid search parameters\n",
    "param_grid= dict(activation_function= activation_function, init=init)\n",
    "#build and fit the gridsearchCV\n",
    "grid= GridSearchCV(estimator=model, param_grid=param_grid, cv= KFold(), verbose=10 )\n",
    "grid_result= grid.fit(x_standerdized,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best:-0.6075028121471405, using {'activation_function': 'linear', 'init': 'uniform'}\n",
      "-0.6075028121471405,0.16633264536205253 with: {'activation_function': 'linear', 'init': 'uniform'}\n",
      "-0.6277311265468597,0.12034170230525439 with: {'activation_function': 'linear', 'init': 'normal'}\n",
      "-15175.9505859375,820.900157811348 with: {'activation_function': 'linear', 'init': 'zero'}\n",
      "-0.7020758926868439,0.1786475455672765 with: {'activation_function': 'relu', 'init': 'uniform'}\n",
      "-0.6861273527145386,0.20180507922159854 with: {'activation_function': 'relu', 'init': 'normal'}\n",
      "-15175.92890625,820.8863703654935 with: {'activation_function': 'relu', 'init': 'zero'}\n"
     ]
    }
   ],
   "source": [
    "# summerize results\n",
    "print('Best:{}, using {}'.format(grid_result.best_score_, grid_result.best_params_))\n",
    "means= grid_result.cv_results_['mean_test_score']\n",
    "stds= grid_result.cv_results_['std_test_score']\n",
    "params= grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "  print('{},{} with: {}'.format(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "[CV] neuron1=4, neuron2=4, neuron3=4 .................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .... neuron1=4, neuron2=4, neuron3=4, score=-0.686, total=   7.6s\n",
      "[CV] neuron1=4, neuron2=4, neuron3=4 .................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    7.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .... neuron1=4, neuron2=4, neuron3=4, score=-0.586, total=   6.8s\n",
      "[CV] neuron1=4, neuron2=4, neuron3=4 .................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:   14.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .... neuron1=4, neuron2=4, neuron3=4, score=-0.627, total=   7.3s\n",
      "[CV] neuron1=4, neuron2=4, neuron3=4 .................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:   21.7s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .... neuron1=4, neuron2=4, neuron3=4, score=-0.471, total=   7.3s\n",
      "[CV] neuron1=4, neuron2=4, neuron3=4 .................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   29.0s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .... neuron1=4, neuron2=4, neuron3=4, score=-0.577, total=   7.4s\n",
      "[CV] neuron1=4, neuron2=4, neuron3=8 .................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:   36.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .... neuron1=4, neuron2=4, neuron3=8, score=-0.850, total=   7.1s\n",
      "[CV] neuron1=4, neuron2=4, neuron3=8 .................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:   43.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .... neuron1=4, neuron2=4, neuron3=8, score=-0.603, total=   6.9s\n",
      "[CV] neuron1=4, neuron2=4, neuron3=8 .................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:   50.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .... neuron1=4, neuron2=4, neuron3=8, score=-0.743, total=   7.1s\n",
      "[CV] neuron1=4, neuron2=4, neuron3=8 .................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:   57.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .... neuron1=4, neuron2=4, neuron3=8, score=-0.638, total=   9.1s\n",
      "[CV] neuron1=4, neuron2=4, neuron3=8 .................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:  1.1min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .... neuron1=4, neuron2=4, neuron3=8, score=-0.684, total=   7.8s\n",
      "[CV] neuron1=4, neuron2=4, neuron3=16 ................................\n",
      "[CV] ... neuron1=4, neuron2=4, neuron3=16, score=-0.837, total=   8.8s\n",
      "[CV] neuron1=4, neuron2=4, neuron3=16 ................................\n",
      "[CV] ... neuron1=4, neuron2=4, neuron3=16, score=-0.422, total=   8.5s\n",
      "[CV] neuron1=4, neuron2=4, neuron3=16 ................................\n",
      "[CV] ... neuron1=4, neuron2=4, neuron3=16, score=-0.690, total=   8.1s\n",
      "[CV] neuron1=4, neuron2=4, neuron3=16 ................................\n",
      "[CV] ... neuron1=4, neuron2=4, neuron3=16, score=-0.474, total=   6.5s\n",
      "[CV] neuron1=4, neuron2=4, neuron3=16 ................................\n",
      "[CV] ... neuron1=4, neuron2=4, neuron3=16, score=-0.553, total=   7.3s\n",
      "[CV] neuron1=4, neuron2=8, neuron3=4 .................................\n",
      "[CV] .... neuron1=4, neuron2=8, neuron3=4, score=-1.014, total=   7.4s\n",
      "[CV] neuron1=4, neuron2=8, neuron3=4 .................................\n",
      "[CV] .... neuron1=4, neuron2=8, neuron3=4, score=-0.446, total=   6.5s\n",
      "[CV] neuron1=4, neuron2=8, neuron3=4 .................................\n",
      "[CV] .... neuron1=4, neuron2=8, neuron3=4, score=-0.684, total=   7.0s\n",
      "[CV] neuron1=4, neuron2=8, neuron3=4 .................................\n",
      "[CV] .... neuron1=4, neuron2=8, neuron3=4, score=-0.574, total=   7.0s\n",
      "[CV] neuron1=4, neuron2=8, neuron3=4 .................................\n",
      "[CV] .... neuron1=4, neuron2=8, neuron3=4, score=-0.616, total=   7.5s\n",
      "[CV] neuron1=4, neuron2=8, neuron3=8 .................................\n",
      "[CV] .... neuron1=4, neuron2=8, neuron3=8, score=-1.292, total=   7.3s\n",
      "[CV] neuron1=4, neuron2=8, neuron3=8 .................................\n",
      "[CV] .... neuron1=4, neuron2=8, neuron3=8, score=-0.529, total=   6.8s\n",
      "[CV] neuron1=4, neuron2=8, neuron3=8 .................................\n",
      "[CV] .... neuron1=4, neuron2=8, neuron3=8, score=-0.753, total=   6.5s\n",
      "[CV] neuron1=4, neuron2=8, neuron3=8 .................................\n",
      "[CV] .... neuron1=4, neuron2=8, neuron3=8, score=-0.448, total=   8.3s\n",
      "[CV] neuron1=4, neuron2=8, neuron3=8 .................................\n",
      "[CV] .... neuron1=4, neuron2=8, neuron3=8, score=-0.533, total=   7.4s\n",
      "[CV] neuron1=4, neuron2=8, neuron3=16 ................................\n",
      "[CV] ... neuron1=4, neuron2=8, neuron3=16, score=-0.838, total=   7.1s\n",
      "[CV] neuron1=4, neuron2=8, neuron3=16 ................................\n",
      "[CV] ... neuron1=4, neuron2=8, neuron3=16, score=-0.659, total=   7.5s\n",
      "[CV] neuron1=4, neuron2=8, neuron3=16 ................................\n",
      "[CV] ... neuron1=4, neuron2=8, neuron3=16, score=-0.659, total=   7.0s\n",
      "[CV] neuron1=4, neuron2=8, neuron3=16 ................................\n",
      "[CV] ... neuron1=4, neuron2=8, neuron3=16, score=-0.512, total=   7.4s\n",
      "[CV] neuron1=4, neuron2=8, neuron3=16 ................................\n",
      "[CV] ... neuron1=4, neuron2=8, neuron3=16, score=-0.771, total=   7.5s\n",
      "[CV] neuron1=4, neuron2=16, neuron3=4 ................................\n",
      "[CV] ... neuron1=4, neuron2=16, neuron3=4, score=-0.767, total=   7.4s\n",
      "[CV] neuron1=4, neuron2=16, neuron3=4 ................................\n",
      "[CV] ... neuron1=4, neuron2=16, neuron3=4, score=-0.625, total=   6.9s\n",
      "[CV] neuron1=4, neuron2=16, neuron3=4 ................................\n",
      "[CV] ... neuron1=4, neuron2=16, neuron3=4, score=-0.811, total=   7.4s\n",
      "[CV] neuron1=4, neuron2=16, neuron3=4 ................................\n",
      "[CV] ... neuron1=4, neuron2=16, neuron3=4, score=-0.495, total=   7.3s\n",
      "[CV] neuron1=4, neuron2=16, neuron3=4 ................................\n",
      "[CV] ... neuron1=4, neuron2=16, neuron3=4, score=-0.738, total=   7.2s\n",
      "[CV] neuron1=4, neuron2=16, neuron3=8 ................................\n",
      "[CV] ... neuron1=4, neuron2=16, neuron3=8, score=-0.752, total=   7.0s\n",
      "[CV] neuron1=4, neuron2=16, neuron3=8 ................................\n",
      "[CV] ... neuron1=4, neuron2=16, neuron3=8, score=-0.701, total=   6.8s\n",
      "[CV] neuron1=4, neuron2=16, neuron3=8 ................................\n",
      "[CV] ... neuron1=4, neuron2=16, neuron3=8, score=-0.687, total=   7.5s\n",
      "[CV] neuron1=4, neuron2=16, neuron3=8 ................................\n",
      "[CV] ... neuron1=4, neuron2=16, neuron3=8, score=-0.571, total=   7.0s\n",
      "[CV] neuron1=4, neuron2=16, neuron3=8 ................................\n",
      "[CV] ... neuron1=4, neuron2=16, neuron3=8, score=-0.526, total=   7.5s\n",
      "[CV] neuron1=4, neuron2=16, neuron3=16 ...............................\n",
      "[CV] .. neuron1=4, neuron2=16, neuron3=16, score=-0.752, total=   6.6s\n",
      "[CV] neuron1=4, neuron2=16, neuron3=16 ...............................\n",
      "[CV] .. neuron1=4, neuron2=16, neuron3=16, score=-0.734, total=   7.2s\n",
      "[CV] neuron1=4, neuron2=16, neuron3=16 ...............................\n",
      "[CV] .. neuron1=4, neuron2=16, neuron3=16, score=-0.635, total=   6.7s\n",
      "[CV] neuron1=4, neuron2=16, neuron3=16 ...............................\n",
      "[CV] .. neuron1=4, neuron2=16, neuron3=16, score=-0.583, total=   7.4s\n",
      "[CV] neuron1=4, neuron2=16, neuron3=16 ...............................\n",
      "[CV] .. neuron1=4, neuron2=16, neuron3=16, score=-0.556, total=   7.6s\n",
      "[CV] neuron1=8, neuron2=4, neuron3=4 .................................\n",
      "[CV] .... neuron1=8, neuron2=4, neuron3=4, score=-0.749, total=   6.9s\n",
      "[CV] neuron1=8, neuron2=4, neuron3=4 .................................\n",
      "[CV] .... neuron1=8, neuron2=4, neuron3=4, score=-0.514, total=   7.3s\n",
      "[CV] neuron1=8, neuron2=4, neuron3=4 .................................\n",
      "[CV] .... neuron1=8, neuron2=4, neuron3=4, score=-0.712, total=   7.1s\n",
      "[CV] neuron1=8, neuron2=4, neuron3=4 .................................\n",
      "[CV] .... neuron1=8, neuron2=4, neuron3=4, score=-0.498, total=   7.5s\n",
      "[CV] neuron1=8, neuron2=4, neuron3=4 .................................\n",
      "[CV] .... neuron1=8, neuron2=4, neuron3=4, score=-0.644, total=   7.4s\n",
      "[CV] neuron1=8, neuron2=4, neuron3=8 .................................\n",
      "[CV] .... neuron1=8, neuron2=4, neuron3=8, score=-0.950, total=   7.3s\n",
      "[CV] neuron1=8, neuron2=4, neuron3=8 .................................\n",
      "[CV] .... neuron1=8, neuron2=4, neuron3=8, score=-0.448, total=   7.3s\n",
      "[CV] neuron1=8, neuron2=4, neuron3=8 .................................\n",
      "[CV] .... neuron1=8, neuron2=4, neuron3=8, score=-0.855, total=   7.4s\n",
      "[CV] neuron1=8, neuron2=4, neuron3=8 .................................\n",
      "[CV] .... neuron1=8, neuron2=4, neuron3=8, score=-0.555, total=   6.8s\n",
      "[CV] neuron1=8, neuron2=4, neuron3=8 .................................\n",
      "[CV] .... neuron1=8, neuron2=4, neuron3=8, score=-0.574, total=   7.0s\n",
      "[CV] neuron1=8, neuron2=4, neuron3=16 ................................\n",
      "[CV] ... neuron1=8, neuron2=4, neuron3=16, score=-0.893, total=   7.2s\n",
      "[CV] neuron1=8, neuron2=4, neuron3=16 ................................\n",
      "[CV] ... neuron1=8, neuron2=4, neuron3=16, score=-0.498, total=   6.6s\n",
      "[CV] neuron1=8, neuron2=4, neuron3=16 ................................\n",
      "[CV] ... neuron1=8, neuron2=4, neuron3=16, score=-0.609, total=   6.7s\n",
      "[CV] neuron1=8, neuron2=4, neuron3=16 ................................\n",
      "[CV] ... neuron1=8, neuron2=4, neuron3=16, score=-0.444, total=   6.9s\n",
      "[CV] neuron1=8, neuron2=4, neuron3=16 ................................\n",
      "[CV] ... neuron1=8, neuron2=4, neuron3=16, score=-0.622, total=   6.9s\n",
      "[CV] neuron1=8, neuron2=8, neuron3=4 .................................\n",
      "[CV] .... neuron1=8, neuron2=8, neuron3=4, score=-0.717, total=   7.3s\n",
      "[CV] neuron1=8, neuron2=8, neuron3=4 .................................\n",
      "[CV] .... neuron1=8, neuron2=8, neuron3=4, score=-0.489, total=   6.9s\n",
      "[CV] neuron1=8, neuron2=8, neuron3=4 .................................\n",
      "[CV] .... neuron1=8, neuron2=8, neuron3=4, score=-0.757, total=   7.3s\n",
      "[CV] neuron1=8, neuron2=8, neuron3=4 .................................\n",
      "[CV] .... neuron1=8, neuron2=8, neuron3=4, score=-0.518, total=   7.4s\n",
      "[CV] neuron1=8, neuron2=8, neuron3=4 .................................\n",
      "[CV] .... neuron1=8, neuron2=8, neuron3=4, score=-0.755, total=   7.5s\n",
      "[CV] neuron1=8, neuron2=8, neuron3=8 .................................\n",
      "[CV] .... neuron1=8, neuron2=8, neuron3=8, score=-0.927, total=   7.4s\n",
      "[CV] neuron1=8, neuron2=8, neuron3=8 .................................\n",
      "[CV] .... neuron1=8, neuron2=8, neuron3=8, score=-0.449, total=   7.2s\n",
      "[CV] neuron1=8, neuron2=8, neuron3=8 .................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .... neuron1=8, neuron2=8, neuron3=8, score=-0.924, total=   6.4s\n",
      "[CV] neuron1=8, neuron2=8, neuron3=8 .................................\n",
      "[CV] .... neuron1=8, neuron2=8, neuron3=8, score=-0.452, total=   7.6s\n",
      "[CV] neuron1=8, neuron2=8, neuron3=8 .................................\n",
      "[CV] .... neuron1=8, neuron2=8, neuron3=8, score=-0.578, total=   7.0s\n",
      "[CV] neuron1=8, neuron2=8, neuron3=16 ................................\n",
      "[CV] ... neuron1=8, neuron2=8, neuron3=16, score=-0.836, total=   6.7s\n",
      "[CV] neuron1=8, neuron2=8, neuron3=16 ................................\n",
      "[CV] ... neuron1=8, neuron2=8, neuron3=16, score=-0.417, total=   7.3s\n",
      "[CV] neuron1=8, neuron2=8, neuron3=16 ................................\n",
      "[CV] ... neuron1=8, neuron2=8, neuron3=16, score=-0.734, total=   7.3s\n",
      "[CV] neuron1=8, neuron2=8, neuron3=16 ................................\n",
      "[CV] ... neuron1=8, neuron2=8, neuron3=16, score=-0.512, total=   6.3s\n",
      "[CV] neuron1=8, neuron2=8, neuron3=16 ................................\n",
      "[CV] ... neuron1=8, neuron2=8, neuron3=16, score=-0.615, total=   6.7s\n",
      "[CV] neuron1=8, neuron2=16, neuron3=4 ................................\n",
      "[CV] ... neuron1=8, neuron2=16, neuron3=4, score=-0.874, total=   6.3s\n",
      "[CV] neuron1=8, neuron2=16, neuron3=4 ................................\n",
      "[CV] ... neuron1=8, neuron2=16, neuron3=4, score=-0.440, total=   7.1s\n",
      "[CV] neuron1=8, neuron2=16, neuron3=4 ................................\n",
      "[CV] ... neuron1=8, neuron2=16, neuron3=4, score=-0.630, total=   6.8s\n",
      "[CV] neuron1=8, neuron2=16, neuron3=4 ................................\n",
      "[CV] ... neuron1=8, neuron2=16, neuron3=4, score=-0.515, total=   7.5s\n",
      "[CV] neuron1=8, neuron2=16, neuron3=4 ................................\n",
      "[CV] ... neuron1=8, neuron2=16, neuron3=4, score=-0.528, total=   6.7s\n",
      "[CV] neuron1=8, neuron2=16, neuron3=8 ................................\n",
      "[CV] ... neuron1=8, neuron2=16, neuron3=8, score=-1.048, total=   7.3s\n",
      "[CV] neuron1=8, neuron2=16, neuron3=8 ................................\n",
      "[CV] ... neuron1=8, neuron2=16, neuron3=8, score=-0.416, total=   6.7s\n",
      "[CV] neuron1=8, neuron2=16, neuron3=8 ................................\n",
      "[CV] ... neuron1=8, neuron2=16, neuron3=8, score=-0.824, total=   6.8s\n",
      "[CV] neuron1=8, neuron2=16, neuron3=8 ................................\n",
      "[CV] ... neuron1=8, neuron2=16, neuron3=8, score=-0.880, total=   7.0s\n",
      "[CV] neuron1=8, neuron2=16, neuron3=8 ................................\n",
      "[CV] ... neuron1=8, neuron2=16, neuron3=8, score=-0.820, total=   7.5s\n",
      "[CV] neuron1=8, neuron2=16, neuron3=16 ...............................\n",
      "[CV] .. neuron1=8, neuron2=16, neuron3=16, score=-1.421, total=   7.3s\n",
      "[CV] neuron1=8, neuron2=16, neuron3=16 ...............................\n",
      "[CV] .. neuron1=8, neuron2=16, neuron3=16, score=-0.563, total=   7.4s\n",
      "[CV] neuron1=8, neuron2=16, neuron3=16 ...............................\n",
      "[CV] .. neuron1=8, neuron2=16, neuron3=16, score=-0.736, total=   7.5s\n",
      "[CV] neuron1=8, neuron2=16, neuron3=16 ...............................\n",
      "[CV] .. neuron1=8, neuron2=16, neuron3=16, score=-0.595, total=   7.4s\n",
      "[CV] neuron1=8, neuron2=16, neuron3=16 ...............................\n",
      "[CV] .. neuron1=8, neuron2=16, neuron3=16, score=-0.819, total=   7.5s\n",
      "[CV] neuron1=16, neuron2=4, neuron3=4 ................................\n",
      "[CV] ... neuron1=16, neuron2=4, neuron3=4, score=-0.851, total=   7.4s\n",
      "[CV] neuron1=16, neuron2=4, neuron3=4 ................................\n",
      "[CV] ... neuron1=16, neuron2=4, neuron3=4, score=-0.566, total=   7.5s\n",
      "[CV] neuron1=16, neuron2=4, neuron3=4 ................................\n",
      "[CV] ... neuron1=16, neuron2=4, neuron3=4, score=-0.669, total=   6.7s\n",
      "[CV] neuron1=16, neuron2=4, neuron3=4 ................................\n",
      "[CV] ... neuron1=16, neuron2=4, neuron3=4, score=-0.429, total=   6.8s\n",
      "[CV] neuron1=16, neuron2=4, neuron3=4 ................................\n",
      "[CV] ... neuron1=16, neuron2=4, neuron3=4, score=-0.646, total=   7.6s\n",
      "[CV] neuron1=16, neuron2=4, neuron3=8 ................................\n",
      "[CV] ... neuron1=16, neuron2=4, neuron3=8, score=-0.799, total=   7.3s\n",
      "[CV] neuron1=16, neuron2=4, neuron3=8 ................................\n",
      "[CV] ... neuron1=16, neuron2=4, neuron3=8, score=-0.683, total=   7.3s\n",
      "[CV] neuron1=16, neuron2=4, neuron3=8 ................................\n",
      "[CV] ... neuron1=16, neuron2=4, neuron3=8, score=-0.597, total=   7.3s\n",
      "[CV] neuron1=16, neuron2=4, neuron3=8 ................................\n",
      "[CV] ... neuron1=16, neuron2=4, neuron3=8, score=-0.457, total=   7.3s\n",
      "[CV] neuron1=16, neuron2=4, neuron3=8 ................................\n",
      "[CV] ... neuron1=16, neuron2=4, neuron3=8, score=-0.510, total=   6.9s\n",
      "[CV] neuron1=16, neuron2=4, neuron3=16 ...............................\n",
      "[CV] .. neuron1=16, neuron2=4, neuron3=16, score=-0.898, total=   6.8s\n",
      "[CV] neuron1=16, neuron2=4, neuron3=16 ...............................\n",
      "[CV] .. neuron1=16, neuron2=4, neuron3=16, score=-0.568, total=   7.0s\n",
      "[CV] neuron1=16, neuron2=4, neuron3=16 ...............................\n",
      "[CV] .. neuron1=16, neuron2=4, neuron3=16, score=-0.674, total=   7.3s\n",
      "[CV] neuron1=16, neuron2=4, neuron3=16 ...............................\n",
      "[CV] .. neuron1=16, neuron2=4, neuron3=16, score=-0.504, total=   7.2s\n",
      "[CV] neuron1=16, neuron2=4, neuron3=16 ...............................\n",
      "[CV] .. neuron1=16, neuron2=4, neuron3=16, score=-0.713, total=   7.1s\n",
      "[CV] neuron1=16, neuron2=8, neuron3=4 ................................\n",
      "[CV] ... neuron1=16, neuron2=8, neuron3=4, score=-0.938, total=   7.4s\n",
      "[CV] neuron1=16, neuron2=8, neuron3=4 ................................\n",
      "[CV] ... neuron1=16, neuron2=8, neuron3=4, score=-0.448, total=   7.3s\n",
      "[CV] neuron1=16, neuron2=8, neuron3=4 ................................\n",
      "[CV] ... neuron1=16, neuron2=8, neuron3=4, score=-0.687, total=   7.4s\n",
      "[CV] neuron1=16, neuron2=8, neuron3=4 ................................\n",
      "[CV] ... neuron1=16, neuron2=8, neuron3=4, score=-0.421, total=   7.4s\n",
      "[CV] neuron1=16, neuron2=8, neuron3=4 ................................\n",
      "[CV] ... neuron1=16, neuron2=8, neuron3=4, score=-0.579, total=   7.0s\n",
      "[CV] neuron1=16, neuron2=8, neuron3=8 ................................\n",
      "[CV] ... neuron1=16, neuron2=8, neuron3=8, score=-0.768, total=   6.5s\n",
      "[CV] neuron1=16, neuron2=8, neuron3=8 ................................\n",
      "[CV] ... neuron1=16, neuron2=8, neuron3=8, score=-0.470, total=   6.6s\n",
      "[CV] neuron1=16, neuron2=8, neuron3=8 ................................\n",
      "[CV] ... neuron1=16, neuron2=8, neuron3=8, score=-0.582, total=   6.9s\n",
      "[CV] neuron1=16, neuron2=8, neuron3=8 ................................\n",
      "[CV] ... neuron1=16, neuron2=8, neuron3=8, score=-0.547, total=   6.4s\n",
      "[CV] neuron1=16, neuron2=8, neuron3=8 ................................\n",
      "[CV] ... neuron1=16, neuron2=8, neuron3=8, score=-0.910, total=   7.4s\n",
      "[CV] neuron1=16, neuron2=8, neuron3=16 ...............................\n",
      "[CV] .. neuron1=16, neuron2=8, neuron3=16, score=-0.860, total=   7.0s\n",
      "[CV] neuron1=16, neuron2=8, neuron3=16 ...............................\n",
      "[CV] .. neuron1=16, neuron2=8, neuron3=16, score=-0.597, total=   7.4s\n",
      "[CV] neuron1=16, neuron2=8, neuron3=16 ...............................\n",
      "[CV] .. neuron1=16, neuron2=8, neuron3=16, score=-0.699, total=   7.3s\n",
      "[CV] neuron1=16, neuron2=8, neuron3=16 ...............................\n",
      "[CV] .. neuron1=16, neuron2=8, neuron3=16, score=-0.490, total=   6.9s\n",
      "[CV] neuron1=16, neuron2=8, neuron3=16 ...............................\n",
      "[CV] .. neuron1=16, neuron2=8, neuron3=16, score=-0.836, total=   7.6s\n",
      "[CV] neuron1=16, neuron2=16, neuron3=4 ...............................\n",
      "[CV] .. neuron1=16, neuron2=16, neuron3=4, score=-0.846, total=   6.6s\n",
      "[CV] neuron1=16, neuron2=16, neuron3=4 ...............................\n",
      "[CV] .. neuron1=16, neuron2=16, neuron3=4, score=-0.918, total=   6.8s\n",
      "[CV] neuron1=16, neuron2=16, neuron3=4 ...............................\n",
      "[CV] .. neuron1=16, neuron2=16, neuron3=4, score=-0.698, total=   6.7s\n",
      "[CV] neuron1=16, neuron2=16, neuron3=4 ...............................\n",
      "[CV] .. neuron1=16, neuron2=16, neuron3=4, score=-0.630, total=   6.5s\n",
      "[CV] neuron1=16, neuron2=16, neuron3=4 ...............................\n",
      "[CV] .. neuron1=16, neuron2=16, neuron3=4, score=-0.696, total=   7.7s\n",
      "[CV] neuron1=16, neuron2=16, neuron3=8 ...............................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .. neuron1=16, neuron2=16, neuron3=8, score=-1.077, total=   6.8s\n",
      "[CV] neuron1=16, neuron2=16, neuron3=8 ...............................\n",
      "[CV] .. neuron1=16, neuron2=16, neuron3=8, score=-0.972, total=   6.7s\n",
      "[CV] neuron1=16, neuron2=16, neuron3=8 ...............................\n",
      "[CV] .. neuron1=16, neuron2=16, neuron3=8, score=-0.652, total=   6.7s\n",
      "[CV] neuron1=16, neuron2=16, neuron3=8 ...............................\n",
      "[CV] .. neuron1=16, neuron2=16, neuron3=8, score=-0.858, total=   7.7s\n",
      "[CV] neuron1=16, neuron2=16, neuron3=8 ...............................\n",
      "[CV] .. neuron1=16, neuron2=16, neuron3=8, score=-0.656, total=   6.8s\n",
      "[CV] neuron1=16, neuron2=16, neuron3=16 ..............................\n",
      "[CV] . neuron1=16, neuron2=16, neuron3=16, score=-1.727, total=   7.4s\n",
      "[CV] neuron1=16, neuron2=16, neuron3=16 ..............................\n",
      "[CV] . neuron1=16, neuron2=16, neuron3=16, score=-0.480, total=   7.4s\n",
      "[CV] neuron1=16, neuron2=16, neuron3=16 ..............................\n",
      "[CV] . neuron1=16, neuron2=16, neuron3=16, score=-0.678, total=   7.4s\n",
      "[CV] neuron1=16, neuron2=16, neuron3=16 ..............................\n",
      "[CV] . neuron1=16, neuron2=16, neuron3=16, score=-0.554, total=   7.4s\n",
      "[CV] neuron1=16, neuron2=16, neuron3=16 ..............................\n",
      "[CV] . neuron1=16, neuron2=16, neuron3=16, score=-0.633, total=   7.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 135 out of 135 | elapsed: 16.1min finished\n"
     ]
    }
   ],
   "source": [
    "def create_model_neuron(neuron1,neuron2, neuron3):\n",
    "  model= Sequential()\n",
    "  model.add(Dense(neuron1, input_dim=10, kernel_initializer= 'normal', activation='linear'))\n",
    "  model.add(Dropout(0))\n",
    "  model.add(Dense(neuron2, kernel_initializer= 'normal', activation='linear'))\n",
    "  model.add(Dropout(0))\n",
    "  model.add(Dense(neuron3, kernel_initializer= 'normal', activation='linear'))\n",
    "  model.add(Dropout(0))\n",
    "  model.add(Dense(1, kernel_initializer= 'normal', activation='linear')) \n",
    "  adam= Adam(learning_rate= 0.001)\n",
    "# Compile model\n",
    "  model.compile(loss='mean_squared_error', optimizer=adam)\n",
    "  return model\n",
    "\n",
    "# Define regression model\n",
    "model= KerasRegressor(build_fn=create_model_neuron, verbose=0, batch_size=100, epochs=100)\n",
    "# Define grid search model\n",
    "neuron1=[4,8,16]\n",
    "neuron2=[4,8,16]\n",
    "neuron3=[4,8,16]\n",
    "# Make a dictionary of grid search parameters\n",
    "param_grid= dict(neuron1= neuron1, neuron2=neuron2,neuron3=neuron3 )\n",
    "#build and fit the gridsearchCV\n",
    "grid= GridSearchCV(estimator=model, param_grid=param_grid, cv= KFold(), verbose=10 )\n",
    "grid_result= grid.fit(x_standerdized,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best:-0.5895180881023407, using {'neuron1': 4, 'neuron2': 4, 'neuron3': 4}\n",
      "-0.5895180881023407,0.07076860698092242 with: {'neuron1': 4, 'neuron2': 4, 'neuron3': 4}\n",
      "-0.7035009860992432,0.08684148775097054 with: {'neuron1': 4, 'neuron2': 4, 'neuron3': 8}\n",
      "-0.595016622543335,0.15104871959505806 with: {'neuron1': 4, 'neuron2': 4, 'neuron3': 16}\n",
      "-0.6667517781257629,0.19039417820079985 with: {'neuron1': 4, 'neuron2': 8, 'neuron3': 4}\n",
      "-0.7110422074794769,0.30752754124348863 with: {'neuron1': 4, 'neuron2': 8, 'neuron3': 8}\n",
      "-0.6877642869949341,0.11131947764392801 with: {'neuron1': 4, 'neuron2': 8, 'neuron3': 16}\n",
      "-0.6873094260692596,0.11403545067847586 with: {'neuron1': 4, 'neuron2': 16, 'neuron3': 4}\n",
      "-0.6475640892982483,0.08488151705748558 with: {'neuron1': 4, 'neuron2': 16, 'neuron3': 8}\n",
      "-0.6519231796264648,0.0787453742214215 with: {'neuron1': 4, 'neuron2': 16, 'neuron3': 16}\n",
      "-0.6235211908817291,0.10161867456051651 with: {'neuron1': 8, 'neuron2': 4, 'neuron3': 4}\n",
      "-0.6765466392040252,0.1919768145543399 with: {'neuron1': 8, 'neuron2': 4, 'neuron3': 8}\n",
      "-0.613482677936554,0.1551824792817041 with: {'neuron1': 8, 'neuron2': 4, 'neuron3': 16}\n",
      "-0.6471661686897278,0.11850709923426918 with: {'neuron1': 8, 'neuron2': 8, 'neuron3': 4}\n",
      "-0.665970629453659,0.21671556746874093 with: {'neuron1': 8, 'neuron2': 8, 'neuron3': 8}\n",
      "-0.6225647270679474,0.1499521237866623 with: {'neuron1': 8, 'neuron2': 8, 'neuron3': 16}\n",
      "-0.5975491762161255,0.15088695669099758 with: {'neuron1': 8, 'neuron2': 16, 'neuron3': 4}\n",
      "-0.7974184274673461,0.20795457122920202 with: {'neuron1': 8, 'neuron2': 16, 'neuron3': 8}\n",
      "-0.8269986987113953,0.3113792772571019 with: {'neuron1': 8, 'neuron2': 16, 'neuron3': 16}\n",
      "-0.6323226988315582,0.1378268052202679 with: {'neuron1': 16, 'neuron2': 4, 'neuron3': 4}\n",
      "-0.6089943051338196,0.12224998593229924 with: {'neuron1': 16, 'neuron2': 4, 'neuron3': 8}\n",
      "-0.6714926600456238,0.135595082027814 with: {'neuron1': 16, 'neuron2': 4, 'neuron3': 16}\n",
      "-0.614827686548233,0.1878608659570244 with: {'neuron1': 16, 'neuron2': 8, 'neuron3': 4}\n",
      "-0.6553198993206024,0.16044016610216225 with: {'neuron1': 16, 'neuron2': 8, 'neuron3': 8}\n",
      "-0.6963891088962555,0.14053973477987905 with: {'neuron1': 16, 'neuron2': 8, 'neuron3': 16}\n",
      "-0.7575044512748719,0.10705807928385642 with: {'neuron1': 16, 'neuron2': 16, 'neuron3': 4}\n",
      "-0.8428035736083984,0.1692101462718692 with: {'neuron1': 16, 'neuron2': 16, 'neuron3': 8}\n",
      "-0.8145996510982514,0.46135007442696246 with: {'neuron1': 16, 'neuron2': 16, 'neuron3': 16}\n"
     ]
    }
   ],
   "source": [
    "print('Best:{}, using {}'.format(grid_result.best_score_, grid_result.best_params_))\n",
    "means= grid_result.cv_results_['mean_test_score']\n",
    "stds= grid_result.cv_results_['std_test_score']\n",
    "params= grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "  print('{},{} with: {}'.format(mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "Epoch 2/100\n",
      "Epoch 3/100\n",
      "Epoch 4/100\n",
      "Epoch 5/100\n",
      "Epoch 6/100\n",
      "Epoch 7/100\n",
      "Epoch 8/100\n",
      "Epoch 9/100\n",
      "Epoch 10/100\n",
      "Epoch 11/100\n",
      "Epoch 12/100\n",
      "Epoch 13/100\n",
      "Epoch 14/100\n",
      "Epoch 15/100\n",
      "Epoch 16/100\n",
      "Epoch 17/100\n",
      "Epoch 18/100\n",
      "Epoch 19/100\n",
      "Epoch 20/100\n",
      "Epoch 21/100\n",
      "Epoch 22/100\n",
      "Epoch 23/100\n",
      "Epoch 24/100\n",
      "Epoch 25/100\n",
      "Epoch 26/100\n",
      "Epoch 27/100\n",
      "Epoch 28/100\n",
      "Epoch 29/100\n",
      "Epoch 30/100\n",
      "Epoch 31/100\n",
      "Epoch 32/100\n",
      "Epoch 33/100\n",
      "Epoch 34/100\n",
      "Epoch 35/100\n",
      "Epoch 36/100\n",
      "Epoch 37/100\n",
      "Epoch 38/100\n",
      "Epoch 39/100\n",
      "Epoch 40/100\n",
      "Epoch 41/100\n",
      "Epoch 42/100\n",
      "Epoch 43/100\n",
      "Epoch 44/100\n",
      "Epoch 45/100\n",
      "Epoch 46/100\n",
      "Epoch 47/100\n",
      "Epoch 48/100\n",
      "Epoch 49/100\n",
      "Epoch 50/100\n",
      "Epoch 51/100\n",
      "Epoch 52/100\n",
      "Epoch 53/100\n",
      "Epoch 54/100\n",
      "Epoch 55/100\n",
      "Epoch 56/100\n",
      "Epoch 57/100\n",
      "Epoch 58/100\n",
      "Epoch 59/100\n",
      "Epoch 60/100\n",
      "Epoch 61/100\n",
      "Epoch 62/100\n",
      "Epoch 63/100\n",
      "Epoch 64/100\n",
      "Epoch 65/100\n",
      "Epoch 66/100\n",
      "Epoch 67/100\n",
      "Epoch 68/100\n",
      "Epoch 69/100\n",
      "Epoch 70/100\n",
      "Epoch 71/100\n",
      "Epoch 72/100\n",
      "Epoch 73/100\n",
      "Epoch 74/100\n",
      "Epoch 75/100\n",
      "Epoch 76/100\n",
      "Epoch 77/100\n",
      "Epoch 78/100\n",
      "Epoch 79/100\n",
      "Epoch 80/100\n",
      "Epoch 81/100\n",
      "Epoch 82/100\n",
      "Epoch 83/100\n",
      "Epoch 84/100\n",
      "Epoch 85/100\n",
      "Epoch 86/100\n",
      "Epoch 87/100\n",
      "Epoch 88/100\n",
      "Epoch 89/100\n",
      "Epoch 90/100\n",
      "Epoch 91/100\n",
      "Epoch 92/100\n",
      "Epoch 93/100\n",
      "Epoch 94/100\n",
      "Epoch 95/100\n",
      "Epoch 96/100\n",
      "Epoch 97/100\n",
      "Epoch 98/100\n",
      "Epoch 99/100\n",
      "Epoch 100/100\n",
      "Epoch 1/100\n",
      "Epoch 2/100\n",
      "Epoch 3/100\n",
      "Epoch 4/100\n",
      "Epoch 5/100\n",
      "Epoch 6/100\n",
      "Epoch 7/100\n",
      "Epoch 8/100\n",
      "Epoch 9/100\n",
      "Epoch 10/100\n",
      "Epoch 11/100\n",
      "Epoch 12/100\n",
      "Epoch 13/100\n",
      "Epoch 14/100\n",
      "Epoch 15/100\n",
      "Epoch 16/100\n",
      "Epoch 17/100\n",
      "Epoch 18/100\n",
      "Epoch 19/100\n",
      "Epoch 20/100\n",
      "Epoch 21/100\n",
      "Epoch 22/100\n",
      "Epoch 23/100\n",
      "Epoch 24/100\n",
      "Epoch 25/100\n",
      "Epoch 26/100\n",
      "Epoch 27/100\n",
      "Epoch 28/100\n",
      "Epoch 29/100\n",
      "Epoch 30/100\n",
      "Epoch 31/100\n",
      "Epoch 32/100\n",
      "Epoch 33/100\n",
      "Epoch 34/100\n",
      "Epoch 35/100\n",
      "Epoch 36/100\n",
      "Epoch 37/100\n",
      "Epoch 38/100\n",
      "Epoch 39/100\n",
      "Epoch 40/100\n",
      "Epoch 41/100\n",
      "Epoch 42/100\n",
      "Epoch 43/100\n",
      "Epoch 44/100\n",
      "Epoch 45/100\n",
      "Epoch 46/100\n",
      "Epoch 47/100\n",
      "Epoch 48/100\n",
      "Epoch 49/100\n",
      "Epoch 50/100\n",
      "Epoch 51/100\n",
      "Epoch 52/100\n",
      "Epoch 53/100\n",
      "Epoch 54/100\n",
      "Epoch 55/100\n",
      "Epoch 56/100\n",
      "Epoch 57/100\n",
      "Epoch 58/100\n",
      "Epoch 59/100\n",
      "Epoch 60/100\n",
      "Epoch 61/100\n",
      "Epoch 62/100\n",
      "Epoch 63/100\n",
      "Epoch 64/100\n",
      "Epoch 65/100\n",
      "Epoch 66/100\n",
      "Epoch 67/100\n",
      "Epoch 68/100\n",
      "Epoch 69/100\n",
      "Epoch 70/100\n",
      "Epoch 71/100\n",
      "Epoch 72/100\n",
      "Epoch 73/100\n",
      "Epoch 74/100\n",
      "Epoch 75/100\n",
      "Epoch 76/100\n",
      "Epoch 77/100\n",
      "Epoch 78/100\n",
      "Epoch 79/100\n",
      "Epoch 80/100\n",
      "Epoch 81/100\n",
      "Epoch 82/100\n",
      "Epoch 83/100\n",
      "Epoch 84/100\n",
      "Epoch 85/100\n",
      "Epoch 86/100\n",
      "Epoch 87/100\n",
      "Epoch 88/100\n",
      "Epoch 89/100\n",
      "Epoch 90/100\n",
      "Epoch 91/100\n",
      "Epoch 92/100\n",
      "Epoch 93/100\n",
      "Epoch 94/100\n",
      "Epoch 95/100\n",
      "Epoch 96/100\n",
      "Epoch 97/100\n",
      "Epoch 98/100\n",
      "Epoch 99/100\n",
      "Epoch 100/100\n",
      "Epoch 1/100\n",
      "Epoch 2/100\n",
      "Epoch 3/100\n",
      "Epoch 4/100\n",
      "Epoch 5/100\n",
      "Epoch 6/100\n",
      "Epoch 7/100\n",
      "Epoch 8/100\n",
      "Epoch 9/100\n",
      "Epoch 10/100\n",
      "Epoch 11/100\n",
      "Epoch 12/100\n",
      "Epoch 13/100\n",
      "Epoch 14/100\n",
      "Epoch 15/100\n",
      "Epoch 16/100\n",
      "Epoch 17/100\n",
      "Epoch 18/100\n",
      "Epoch 19/100\n",
      "Epoch 20/100\n",
      "Epoch 21/100\n",
      "Epoch 22/100\n",
      "Epoch 23/100\n",
      "Epoch 24/100\n",
      "Epoch 25/100\n",
      "Epoch 26/100\n",
      "Epoch 27/100\n",
      "Epoch 28/100\n",
      "Epoch 29/100\n",
      "Epoch 30/100\n",
      "Epoch 31/100\n",
      "Epoch 32/100\n",
      "Epoch 33/100\n",
      "Epoch 34/100\n",
      "Epoch 35/100\n",
      "Epoch 36/100\n",
      "Epoch 37/100\n",
      "Epoch 38/100\n",
      "Epoch 39/100\n",
      "Epoch 40/100\n",
      "Epoch 41/100\n",
      "Epoch 42/100\n",
      "Epoch 43/100\n",
      "Epoch 44/100\n",
      "Epoch 45/100\n",
      "Epoch 46/100\n",
      "Epoch 47/100\n",
      "Epoch 48/100\n",
      "Epoch 49/100\n",
      "Epoch 50/100\n",
      "Epoch 51/100\n",
      "Epoch 52/100\n",
      "Epoch 53/100\n",
      "Epoch 54/100\n",
      "Epoch 55/100\n",
      "Epoch 56/100\n",
      "Epoch 57/100\n",
      "Epoch 58/100\n",
      "Epoch 59/100\n",
      "Epoch 60/100\n",
      "Epoch 61/100\n",
      "Epoch 62/100\n",
      "Epoch 63/100\n",
      "Epoch 64/100\n",
      "Epoch 65/100\n",
      "Epoch 66/100\n",
      "Epoch 67/100\n",
      "Epoch 68/100\n",
      "Epoch 69/100\n",
      "Epoch 70/100\n",
      "Epoch 71/100\n",
      "Epoch 72/100\n",
      "Epoch 73/100\n",
      "Epoch 74/100\n",
      "Epoch 75/100\n",
      "Epoch 76/100\n",
      "Epoch 77/100\n",
      "Epoch 78/100\n",
      "Epoch 79/100\n",
      "Epoch 80/100\n",
      "Epoch 81/100\n",
      "Epoch 82/100\n",
      "Epoch 83/100\n",
      "Epoch 84/100\n",
      "Epoch 85/100\n",
      "Epoch 86/100\n",
      "Epoch 87/100\n",
      "Epoch 88/100\n",
      "Epoch 89/100\n",
      "Epoch 90/100\n",
      "Epoch 91/100\n",
      "Epoch 92/100\n",
      "Epoch 93/100\n",
      "Epoch 94/100\n",
      "Epoch 95/100\n",
      "Epoch 96/100\n",
      "Epoch 97/100\n",
      "Epoch 98/100\n",
      "Epoch 99/100\n",
      "Epoch 100/100\n",
      "Epoch 1/100\n",
      "Epoch 2/100\n",
      "Epoch 3/100\n",
      "Epoch 4/100\n",
      "Epoch 5/100\n",
      "Epoch 6/100\n",
      "Epoch 7/100\n",
      "Epoch 8/100\n",
      "Epoch 9/100\n",
      "Epoch 10/100\n",
      "Epoch 11/100\n",
      "Epoch 12/100\n",
      "Epoch 13/100\n",
      "Epoch 14/100\n",
      "Epoch 15/100\n",
      "Epoch 16/100\n",
      "Epoch 17/100\n",
      "Epoch 18/100\n",
      "Epoch 19/100\n",
      "Epoch 20/100\n",
      "Epoch 21/100\n",
      "Epoch 22/100\n",
      "Epoch 23/100\n",
      "Epoch 24/100\n",
      "Epoch 25/100\n",
      "Epoch 26/100\n",
      "Epoch 27/100\n",
      "Epoch 28/100\n",
      "Epoch 29/100\n",
      "Epoch 30/100\n",
      "Epoch 31/100\n",
      "Epoch 32/100\n",
      "Epoch 33/100\n",
      "Epoch 34/100\n",
      "Epoch 35/100\n",
      "Epoch 36/100\n",
      "Epoch 37/100\n",
      "Epoch 38/100\n",
      "Epoch 39/100\n",
      "Epoch 40/100\n",
      "Epoch 41/100\n",
      "Epoch 42/100\n",
      "Epoch 43/100\n",
      "Epoch 44/100\n",
      "Epoch 45/100\n",
      "Epoch 46/100\n",
      "Epoch 47/100\n",
      "Epoch 48/100\n",
      "Epoch 49/100\n",
      "Epoch 50/100\n",
      "Epoch 51/100\n",
      "Epoch 52/100\n",
      "Epoch 53/100\n",
      "Epoch 54/100\n",
      "Epoch 55/100\n",
      "Epoch 56/100\n",
      "Epoch 57/100\n",
      "Epoch 58/100\n",
      "Epoch 59/100\n",
      "Epoch 60/100\n",
      "Epoch 61/100\n",
      "Epoch 62/100\n",
      "Epoch 63/100\n",
      "Epoch 64/100\n",
      "Epoch 65/100\n",
      "Epoch 66/100\n",
      "Epoch 67/100\n",
      "Epoch 68/100\n",
      "Epoch 69/100\n",
      "Epoch 70/100\n",
      "Epoch 71/100\n",
      "Epoch 72/100\n",
      "Epoch 73/100\n",
      "Epoch 74/100\n",
      "Epoch 75/100\n",
      "Epoch 76/100\n",
      "Epoch 77/100\n",
      "Epoch 78/100\n",
      "Epoch 79/100\n",
      "Epoch 80/100\n",
      "Epoch 81/100\n",
      "Epoch 82/100\n",
      "Epoch 83/100\n",
      "Epoch 84/100\n",
      "Epoch 85/100\n",
      "Epoch 86/100\n",
      "Epoch 87/100\n",
      "Epoch 88/100\n",
      "Epoch 89/100\n",
      "Epoch 90/100\n",
      "Epoch 91/100\n",
      "Epoch 92/100\n",
      "Epoch 93/100\n",
      "Epoch 94/100\n",
      "Epoch 95/100\n",
      "Epoch 96/100\n",
      "Epoch 97/100\n",
      "Epoch 98/100\n",
      "Epoch 99/100\n",
      "Epoch 100/100\n",
      "Epoch 1/100\n",
      "Epoch 2/100\n",
      "Epoch 3/100\n",
      "Epoch 4/100\n",
      "Epoch 5/100\n",
      "Epoch 6/100\n",
      "Epoch 7/100\n",
      "Epoch 8/100\n",
      "Epoch 9/100\n",
      "Epoch 10/100\n",
      "Epoch 11/100\n",
      "Epoch 12/100\n",
      "Epoch 13/100\n",
      "Epoch 14/100\n",
      "Epoch 15/100\n",
      "Epoch 16/100\n",
      "Epoch 17/100\n",
      "Epoch 18/100\n",
      "Epoch 19/100\n",
      "Epoch 20/100\n",
      "Epoch 21/100\n",
      "Epoch 22/100\n",
      "Epoch 23/100\n",
      "Epoch 24/100\n",
      "Epoch 25/100\n",
      "Epoch 26/100\n",
      "Epoch 27/100\n",
      "Epoch 28/100\n",
      "Epoch 29/100\n",
      "Epoch 30/100\n",
      "Epoch 31/100\n",
      "Epoch 32/100\n",
      "Epoch 33/100\n",
      "Epoch 34/100\n",
      "Epoch 35/100\n",
      "Epoch 36/100\n",
      "Epoch 37/100\n",
      "Epoch 38/100\n",
      "Epoch 39/100\n",
      "Epoch 40/100\n",
      "Epoch 41/100\n",
      "Epoch 42/100\n",
      "Epoch 43/100\n",
      "Epoch 44/100\n",
      "Epoch 45/100\n",
      "Epoch 46/100\n",
      "Epoch 47/100\n",
      "Epoch 48/100\n",
      "Epoch 49/100\n",
      "Epoch 50/100\n",
      "Epoch 51/100\n",
      "Epoch 52/100\n",
      "Epoch 53/100\n",
      "Epoch 54/100\n",
      "Epoch 55/100\n",
      "Epoch 56/100\n",
      "Epoch 57/100\n",
      "Epoch 58/100\n",
      "Epoch 59/100\n",
      "Epoch 60/100\n",
      "Epoch 61/100\n",
      "Epoch 62/100\n",
      "Epoch 63/100\n",
      "Epoch 64/100\n",
      "Epoch 65/100\n",
      "Epoch 66/100\n",
      "Epoch 67/100\n",
      "Epoch 68/100\n",
      "Epoch 69/100\n",
      "Epoch 70/100\n",
      "Epoch 71/100\n",
      "Epoch 72/100\n",
      "Epoch 73/100\n",
      "Epoch 74/100\n",
      "Epoch 75/100\n",
      "Epoch 76/100\n",
      "Epoch 77/100\n",
      "Epoch 78/100\n",
      "Epoch 79/100\n",
      "Epoch 80/100\n",
      "Epoch 81/100\n",
      "Epoch 82/100\n",
      "Epoch 83/100\n",
      "Epoch 84/100\n",
      "Epoch 85/100\n",
      "Epoch 86/100\n",
      "Epoch 87/100\n",
      "Epoch 88/100\n",
      "Epoch 89/100\n",
      "Epoch 90/100\n",
      "Epoch 91/100\n",
      "Epoch 92/100\n",
      "Epoch 93/100\n",
      "Epoch 94/100\n",
      "Epoch 95/100\n",
      "Epoch 96/100\n",
      "Epoch 97/100\n",
      "Epoch 98/100\n",
      "Epoch 99/100\n",
      "Epoch 100/100\n",
      "Epoch 1/100\n",
      "Epoch 2/100\n",
      "Epoch 3/100\n",
      "Epoch 4/100\n",
      "Epoch 5/100\n",
      "Epoch 6/100\n",
      "Epoch 7/100\n",
      "Epoch 8/100\n",
      "Epoch 9/100\n",
      "Epoch 10/100\n",
      "Epoch 11/100\n",
      "Epoch 12/100\n",
      "Epoch 13/100\n",
      "Epoch 14/100\n",
      "Epoch 15/100\n",
      "Epoch 16/100\n",
      "Epoch 17/100\n",
      "Epoch 18/100\n",
      "Epoch 19/100\n",
      "Epoch 20/100\n",
      "Epoch 21/100\n",
      "Epoch 22/100\n",
      "Epoch 23/100\n",
      "Epoch 24/100\n",
      "Epoch 25/100\n",
      "Epoch 26/100\n",
      "Epoch 27/100\n",
      "Epoch 28/100\n",
      "Epoch 29/100\n",
      "Epoch 30/100\n",
      "Epoch 31/100\n",
      "Epoch 32/100\n",
      "Epoch 33/100\n",
      "Epoch 34/100\n",
      "Epoch 35/100\n",
      "Epoch 36/100\n",
      "Epoch 37/100\n",
      "Epoch 38/100\n",
      "Epoch 39/100\n",
      "Epoch 40/100\n",
      "Epoch 41/100\n",
      "Epoch 42/100\n",
      "Epoch 43/100\n",
      "Epoch 44/100\n",
      "Epoch 45/100\n",
      "Epoch 46/100\n",
      "Epoch 47/100\n",
      "Epoch 48/100\n",
      "Epoch 49/100\n",
      "Epoch 50/100\n",
      "Epoch 51/100\n",
      "Epoch 52/100\n",
      "Epoch 53/100\n",
      "Epoch 54/100\n",
      "Epoch 55/100\n",
      "Epoch 56/100\n",
      "Epoch 57/100\n",
      "Epoch 58/100\n",
      "Epoch 59/100\n",
      "Epoch 60/100\n",
      "Epoch 61/100\n",
      "Epoch 62/100\n",
      "Epoch 63/100\n",
      "Epoch 64/100\n",
      "Epoch 65/100\n",
      "Epoch 66/100\n",
      "Epoch 67/100\n",
      "Epoch 68/100\n",
      "Epoch 69/100\n",
      "Epoch 70/100\n",
      "Epoch 71/100\n",
      "Epoch 72/100\n",
      "Epoch 73/100\n",
      "Epoch 74/100\n",
      "Epoch 75/100\n",
      "Epoch 76/100\n",
      "Epoch 77/100\n",
      "Epoch 78/100\n",
      "Epoch 79/100\n",
      "Epoch 80/100\n",
      "Epoch 81/100\n",
      "Epoch 82/100\n",
      "Epoch 83/100\n",
      "Epoch 84/100\n",
      "Epoch 85/100\n",
      "Epoch 86/100\n",
      "Epoch 87/100\n",
      "Epoch 88/100\n",
      "Epoch 89/100\n",
      "Epoch 90/100\n",
      "Epoch 91/100\n",
      "Epoch 92/100\n",
      "Epoch 93/100\n",
      "Epoch 94/100\n",
      "Epoch 95/100\n",
      "Epoch 96/100\n",
      "Epoch 97/100\n",
      "Epoch 98/100\n",
      "Epoch 99/100\n",
      "Epoch 100/100\n",
      "Epoch 1/100\n",
      "Epoch 2/100\n",
      "Epoch 3/100\n",
      "Epoch 4/100\n",
      "Epoch 5/100\n",
      "Epoch 6/100\n",
      "Epoch 7/100\n",
      "Epoch 8/100\n",
      "Epoch 9/100\n",
      "Epoch 10/100\n",
      "Epoch 11/100\n",
      "Epoch 12/100\n",
      "Epoch 13/100\n",
      "Epoch 14/100\n",
      "Epoch 15/100\n",
      "Epoch 16/100\n",
      "Epoch 17/100\n",
      "Epoch 18/100\n",
      "Epoch 19/100\n",
      "Epoch 20/100\n",
      "Epoch 21/100\n",
      "Epoch 22/100\n",
      "Epoch 23/100\n",
      "Epoch 24/100\n",
      "Epoch 25/100\n",
      "Epoch 26/100\n",
      "Epoch 27/100\n",
      "Epoch 28/100\n",
      "Epoch 29/100\n",
      "Epoch 30/100\n",
      "Epoch 31/100\n",
      "Epoch 32/100\n",
      "Epoch 33/100\n",
      "Epoch 34/100\n",
      "Epoch 35/100\n",
      "Epoch 36/100\n",
      "Epoch 37/100\n",
      "Epoch 38/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/100\n",
      "Epoch 40/100\n",
      "Epoch 41/100\n",
      "Epoch 42/100\n",
      "Epoch 43/100\n",
      "Epoch 44/100\n",
      "Epoch 45/100\n",
      "Epoch 46/100\n",
      "Epoch 47/100\n",
      "Epoch 48/100\n",
      "Epoch 49/100\n",
      "Epoch 50/100\n",
      "Epoch 51/100\n",
      "Epoch 52/100\n",
      "Epoch 53/100\n",
      "Epoch 54/100\n",
      "Epoch 55/100\n",
      "Epoch 56/100\n",
      "Epoch 57/100\n",
      "Epoch 58/100\n",
      "Epoch 59/100\n",
      "Epoch 60/100\n",
      "Epoch 61/100\n",
      "Epoch 62/100\n",
      "Epoch 63/100\n",
      "Epoch 64/100\n",
      "Epoch 65/100\n",
      "Epoch 66/100\n",
      "Epoch 67/100\n",
      "Epoch 68/100\n",
      "Epoch 69/100\n",
      "Epoch 70/100\n",
      "Epoch 71/100\n",
      "Epoch 72/100\n",
      "Epoch 73/100\n",
      "Epoch 74/100\n",
      "Epoch 75/100\n",
      "Epoch 76/100\n",
      "Epoch 77/100\n",
      "Epoch 78/100\n",
      "Epoch 79/100\n",
      "Epoch 80/100\n",
      "Epoch 81/100\n",
      "Epoch 82/100\n",
      "Epoch 83/100\n",
      "Epoch 84/100\n",
      "Epoch 85/100\n",
      "Epoch 86/100\n",
      "Epoch 87/100\n",
      "Epoch 88/100\n",
      "Epoch 89/100\n",
      "Epoch 90/100\n",
      "Epoch 91/100\n",
      "Epoch 92/100\n",
      "Epoch 93/100\n",
      "Epoch 94/100\n",
      "Epoch 95/100\n",
      "Epoch 96/100\n",
      "Epoch 97/100\n",
      "Epoch 98/100\n",
      "Epoch 99/100\n",
      "Epoch 100/100\n",
      "Epoch 1/100\n",
      "Epoch 2/100\n",
      "Epoch 3/100\n",
      "Epoch 4/100\n",
      "Epoch 5/100\n",
      "Epoch 6/100\n",
      "Epoch 7/100\n",
      "Epoch 8/100\n",
      "Epoch 9/100\n",
      "Epoch 10/100\n",
      "Epoch 11/100\n",
      "Epoch 12/100\n",
      "Epoch 13/100\n",
      "Epoch 14/100\n",
      "Epoch 15/100\n",
      "Epoch 16/100\n",
      "Epoch 17/100\n",
      "Epoch 18/100\n",
      "Epoch 19/100\n",
      "Epoch 20/100\n",
      "Epoch 21/100\n",
      "Epoch 22/100\n",
      "Epoch 23/100\n",
      "Epoch 24/100\n",
      "Epoch 25/100\n",
      "Epoch 26/100\n",
      "Epoch 27/100\n",
      "Epoch 28/100\n",
      "Epoch 29/100\n",
      "Epoch 30/100\n",
      "Epoch 31/100\n",
      "Epoch 32/100\n",
      "Epoch 33/100\n",
      "Epoch 34/100\n",
      "Epoch 35/100\n",
      "Epoch 36/100\n",
      "Epoch 37/100\n",
      "Epoch 38/100\n",
      "Epoch 39/100\n",
      "Epoch 40/100\n",
      "Epoch 41/100\n",
      "Epoch 42/100\n",
      "Epoch 43/100\n",
      "Epoch 44/100\n",
      "Epoch 45/100\n",
      "Epoch 46/100\n",
      "Epoch 47/100\n",
      "Epoch 48/100\n",
      "Epoch 49/100\n",
      "Epoch 50/100\n",
      "Epoch 51/100\n",
      "Epoch 52/100\n",
      "Epoch 53/100\n",
      "Epoch 54/100\n",
      "Epoch 55/100\n",
      "Epoch 56/100\n",
      "Epoch 57/100\n",
      "Epoch 58/100\n",
      "Epoch 59/100\n",
      "Epoch 60/100\n",
      "Epoch 61/100\n",
      "Epoch 62/100\n",
      "Epoch 63/100\n",
      "Epoch 64/100\n",
      "Epoch 65/100\n",
      "Epoch 66/100\n",
      "Epoch 67/100\n",
      "Epoch 68/100\n",
      "Epoch 69/100\n",
      "Epoch 70/100\n",
      "Epoch 71/100\n",
      "Epoch 72/100\n",
      "Epoch 73/100\n",
      "Epoch 74/100\n",
      "Epoch 75/100\n",
      "Epoch 76/100\n",
      "Epoch 77/100\n",
      "Epoch 78/100\n",
      "Epoch 79/100\n",
      "Epoch 80/100\n",
      "Epoch 81/100\n",
      "Epoch 82/100\n",
      "Epoch 83/100\n",
      "Epoch 84/100\n",
      "Epoch 85/100\n",
      "Epoch 86/100\n",
      "Epoch 87/100\n",
      "Epoch 88/100\n",
      "Epoch 89/100\n",
      "Epoch 90/100\n",
      "Epoch 91/100\n",
      "Epoch 92/100\n",
      "Epoch 93/100\n",
      "Epoch 94/100\n",
      "Epoch 95/100\n",
      "Epoch 96/100\n",
      "Epoch 97/100\n",
      "Epoch 98/100\n",
      "Epoch 99/100\n",
      "Epoch 100/100\n",
      "Epoch 1/100\n",
      "Epoch 2/100\n",
      "Epoch 3/100\n",
      "Epoch 4/100\n",
      "Epoch 5/100\n",
      "Epoch 6/100\n",
      "Epoch 7/100\n",
      "Epoch 8/100\n",
      "Epoch 9/100\n",
      "Epoch 10/100\n",
      "Epoch 11/100\n",
      "Epoch 12/100\n",
      "Epoch 13/100\n",
      "Epoch 14/100\n",
      "Epoch 15/100\n",
      "Epoch 16/100\n",
      "Epoch 17/100\n",
      "Epoch 18/100\n",
      "Epoch 19/100\n",
      "Epoch 20/100\n",
      "Epoch 21/100\n",
      "Epoch 22/100\n",
      "Epoch 23/100\n",
      "Epoch 24/100\n",
      "Epoch 25/100\n",
      "Epoch 26/100\n",
      "Epoch 27/100\n",
      "Epoch 28/100\n",
      "Epoch 29/100\n",
      "Epoch 30/100\n",
      "Epoch 31/100\n",
      "Epoch 32/100\n",
      "Epoch 33/100\n",
      "Epoch 34/100\n",
      "Epoch 35/100\n",
      "Epoch 36/100\n",
      "Epoch 37/100\n",
      "Epoch 38/100\n",
      "Epoch 39/100\n",
      "Epoch 40/100\n",
      "Epoch 41/100\n",
      "Epoch 42/100\n",
      "Epoch 43/100\n",
      "Epoch 44/100\n",
      "Epoch 45/100\n",
      "Epoch 46/100\n",
      "Epoch 47/100\n",
      "Epoch 48/100\n",
      "Epoch 49/100\n",
      "Epoch 50/100\n",
      "Epoch 51/100\n",
      "Epoch 52/100\n",
      "Epoch 53/100\n",
      "Epoch 54/100\n",
      "Epoch 55/100\n",
      "Epoch 56/100\n",
      "Epoch 57/100\n",
      "Epoch 58/100\n",
      "Epoch 59/100\n",
      "Epoch 60/100\n",
      "Epoch 61/100\n",
      "Epoch 62/100\n",
      "Epoch 63/100\n",
      "Epoch 64/100\n",
      "Epoch 65/100\n",
      "Epoch 66/100\n",
      "Epoch 67/100\n",
      "Epoch 68/100\n",
      "Epoch 69/100\n",
      "Epoch 70/100\n",
      "Epoch 71/100\n",
      "Epoch 72/100\n",
      "Epoch 73/100\n",
      "Epoch 74/100\n",
      "Epoch 75/100\n",
      "Epoch 76/100\n",
      "Epoch 77/100\n",
      "Epoch 78/100\n",
      "Epoch 79/100\n",
      "Epoch 80/100\n",
      "Epoch 81/100\n",
      "Epoch 82/100\n",
      "Epoch 83/100\n",
      "Epoch 84/100\n",
      "Epoch 85/100\n",
      "Epoch 86/100\n",
      "Epoch 87/100\n",
      "Epoch 88/100\n",
      "Epoch 89/100\n",
      "Epoch 90/100\n",
      "Epoch 91/100\n",
      "Epoch 92/100\n",
      "Epoch 93/100\n",
      "Epoch 94/100\n",
      "Epoch 95/100\n",
      "Epoch 96/100\n",
      "Epoch 97/100\n",
      "Epoch 98/100\n",
      "Epoch 99/100\n",
      "Epoch 100/100\n",
      "Epoch 1/100\n",
      "Epoch 2/100\n",
      "Epoch 3/100\n",
      "Epoch 4/100\n",
      "Epoch 5/100\n",
      "Epoch 6/100\n",
      "Epoch 7/100\n",
      "Epoch 8/100\n",
      "Epoch 9/100\n",
      "Epoch 10/100\n",
      "Epoch 11/100\n",
      "Epoch 12/100\n",
      "Epoch 13/100\n",
      "Epoch 14/100\n",
      "Epoch 15/100\n",
      "Epoch 16/100\n",
      "Epoch 17/100\n",
      "Epoch 18/100\n",
      "Epoch 19/100\n",
      "Epoch 20/100\n",
      "Epoch 21/100\n",
      "Epoch 22/100\n",
      "Epoch 23/100\n",
      "Epoch 24/100\n",
      "Epoch 25/100\n",
      "Epoch 26/100\n",
      "Epoch 27/100\n",
      "Epoch 28/100\n",
      "Epoch 29/100\n",
      "Epoch 30/100\n",
      "Epoch 31/100\n",
      "Epoch 32/100\n",
      "Epoch 33/100\n",
      "Epoch 34/100\n",
      "Epoch 35/100\n",
      "Epoch 36/100\n",
      "Epoch 37/100\n",
      "Epoch 38/100\n",
      "Epoch 39/100\n",
      "Epoch 40/100\n",
      "Epoch 41/100\n",
      "Epoch 42/100\n",
      "Epoch 43/100\n",
      "Epoch 44/100\n",
      "Epoch 45/100\n",
      "Epoch 46/100\n",
      "Epoch 47/100\n",
      "Epoch 48/100\n",
      "Epoch 49/100\n",
      "Epoch 50/100\n",
      "Epoch 51/100\n",
      "Epoch 52/100\n",
      "Epoch 53/100\n",
      "Epoch 54/100\n",
      "Epoch 55/100\n",
      "Epoch 56/100\n",
      "Epoch 57/100\n",
      "Epoch 58/100\n",
      "Epoch 59/100\n",
      "Epoch 60/100\n",
      "Epoch 61/100\n",
      "Epoch 62/100\n",
      "Epoch 63/100\n",
      "Epoch 64/100\n",
      "Epoch 65/100\n",
      "Epoch 66/100\n",
      "Epoch 67/100\n",
      "Epoch 68/100\n",
      "Epoch 69/100\n",
      "Epoch 70/100\n",
      "Epoch 71/100\n",
      "Epoch 72/100\n",
      "Epoch 73/100\n",
      "Epoch 74/100\n",
      "Epoch 75/100\n",
      "Epoch 76/100\n",
      "Epoch 77/100\n",
      "Epoch 78/100\n",
      "Epoch 79/100\n",
      "Epoch 80/100\n",
      "Epoch 81/100\n",
      "Epoch 82/100\n",
      "Epoch 83/100\n",
      "Epoch 84/100\n",
      "Epoch 85/100\n",
      "Epoch 86/100\n",
      "Epoch 87/100\n",
      "Epoch 88/100\n",
      "Epoch 89/100\n",
      "Epoch 90/100\n",
      "Epoch 91/100\n",
      "Epoch 92/100\n",
      "Epoch 93/100\n",
      "Epoch 94/100\n",
      "Epoch 95/100\n",
      "Epoch 96/100\n",
      "Epoch 97/100\n",
      "Epoch 98/100\n",
      "Epoch 99/100\n",
      "Epoch 100/100\n",
      "Epoch 1/100\n",
      "Epoch 2/100\n",
      "Epoch 3/100\n",
      "Epoch 4/100\n",
      "Epoch 5/100\n",
      "Epoch 6/100\n",
      "Epoch 7/100\n",
      "Epoch 8/100\n",
      "Epoch 9/100\n",
      "Epoch 10/100\n",
      "Epoch 11/100\n",
      "Epoch 12/100\n",
      "Epoch 13/100\n",
      "Epoch 14/100\n",
      "Epoch 15/100\n",
      "Epoch 16/100\n",
      "Epoch 17/100\n",
      "Epoch 18/100\n",
      "Epoch 19/100\n",
      "Epoch 20/100\n",
      "Epoch 21/100\n",
      "Epoch 22/100\n",
      "Epoch 23/100\n",
      "Epoch 24/100\n",
      "Epoch 25/100\n",
      "Epoch 26/100\n",
      "Epoch 27/100\n",
      "Epoch 28/100\n",
      "Epoch 29/100\n",
      "Epoch 30/100\n",
      "Epoch 31/100\n",
      "Epoch 32/100\n",
      "Epoch 33/100\n",
      "Epoch 34/100\n",
      "Epoch 35/100\n",
      "Epoch 36/100\n",
      "Epoch 37/100\n",
      "Epoch 38/100\n",
      "Epoch 39/100\n",
      "Epoch 40/100\n",
      "Epoch 41/100\n",
      "Epoch 42/100\n",
      "Epoch 43/100\n",
      "Epoch 44/100\n",
      "Epoch 45/100\n",
      "Epoch 46/100\n",
      "Epoch 47/100\n",
      "Epoch 48/100\n",
      "Epoch 49/100\n",
      "Epoch 50/100\n",
      "Epoch 51/100\n",
      "Epoch 52/100\n",
      "Epoch 53/100\n",
      "Epoch 54/100\n",
      "Epoch 55/100\n",
      "Epoch 56/100\n",
      "Epoch 57/100\n",
      "Epoch 58/100\n",
      "Epoch 59/100\n",
      "Epoch 60/100\n",
      "Epoch 61/100\n",
      "Epoch 62/100\n",
      "Epoch 63/100\n",
      "Epoch 64/100\n",
      "Epoch 65/100\n",
      "Epoch 66/100\n",
      "Epoch 67/100\n",
      "Epoch 68/100\n",
      "Epoch 69/100\n",
      "Epoch 70/100\n",
      "Epoch 71/100\n",
      "Epoch 72/100\n",
      "Epoch 73/100\n",
      "Epoch 74/100\n",
      "Epoch 75/100\n",
      "Epoch 76/100\n",
      "Epoch 77/100\n",
      "Epoch 78/100\n",
      "Epoch 79/100\n",
      "Epoch 80/100\n",
      "Epoch 81/100\n",
      "Epoch 82/100\n",
      "Epoch 83/100\n",
      "Epoch 84/100\n",
      "Epoch 85/100\n",
      "Epoch 86/100\n",
      "Epoch 87/100\n",
      "Epoch 88/100\n",
      "Epoch 89/100\n",
      "Epoch 90/100\n",
      "Epoch 91/100\n",
      "Epoch 92/100\n",
      "Epoch 93/100\n",
      "Epoch 94/100\n",
      "Epoch 95/100\n",
      "Epoch 96/100\n",
      "Epoch 97/100\n",
      "Epoch 98/100\n",
      "Epoch 99/100\n",
      "Epoch 100/100\n",
      "mse: -0.5845979571342468\n"
     ]
    }
   ],
   "source": [
    "def create_model_opt():\n",
    "  model= Sequential()\n",
    "  model.add(Dense(16, input_dim=10, kernel_initializer= 'normal', activation='linear'))\n",
    "  model.add(Dropout(0))\n",
    "  model.add(Dense(8, kernel_initializer= 'normal', activation='linear'))\n",
    "  model.add(Dropout(0))\n",
    "  model.add(Dense(8, kernel_initializer= 'normal', activation='linear'))\n",
    "  model.add(Dropout(0))\n",
    "  model.add(Dense(1, kernel_initializer= 'normal', activation='linear')) \n",
    "  adam= Adam(learning_rate= 0.001)\n",
    "# Compile model\n",
    "  model.compile(loss='mean_squared_error', optimizer=adam)\n",
    "  return model\n",
    "\n",
    "# Define regression model\n",
    "model= KerasRegressor(build_fn=create_model_opt, verbose=10, batch_size=100, epochs=100)\n",
    "# Fitting model\n",
    "estimator= model.fit(x_standerdized,y)\n",
    "kfold= KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "results= cross_val_score(model, x_standerdized,y, cv= kfold)\n",
    "print('mse:', results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE -0.5845979571342468\n"
     ]
    }
   ],
   "source": [
    "print('MSE',results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
